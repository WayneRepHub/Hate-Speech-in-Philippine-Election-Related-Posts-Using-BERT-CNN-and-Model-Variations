{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5486b8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from transformers import AdamW\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import csv\n",
    "import re\n",
    "import validators\n",
    "import emoji\n",
    "import unidecode\n",
    "import nltk\n",
    "import pickle\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6954a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "SEED = 1235\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# BERT Hyperparameters (ADDITION)\n",
    "n_bert_layers = 16  # Assuming the base model has 12 layers\n",
    "bert_lr = 0.001\n",
    "pooling_strategy = 'cls'  # Options: 'cls', 'mean', 'max'\n",
    "bert_hidden_size = 768  # Adjust based on your BERT model\n",
    "max_seq_length = 128\n",
    "fine_tune_strategy = 'full'  # Options: 'full', 'last_layer'\n",
    "bert_dropout = 0.9  # Adjust based on BERT model specifications\n",
    "\n",
    "max_seq_length = 128  # This should match the max_seq_length used in BERT model\n",
    "padding_strategy = 'max_length'  # Options: 'max_length', 'do_not_pad', 'longest'\n",
    "truncation_strategy = 'longest_first'  # Options: 'longest_first', 'only_first', 'only_second'\n",
    "do_lower_case = True  # Set to False if using a cased model\n",
    "\n",
    "config = BertConfig(\n",
    "    num_hidden_layers=n_bert_layers,\n",
    "    hidden_size=bert_hidden_size,\n",
    "    num_attention_heads=24,  # Assuming 12 attention heads\n",
    "    intermediate_size=4 * bert_hidden_size,  # Default value in BERT\n",
    "    hidden_dropout_prob=bert_dropout,\n",
    "    attention_probs_dropout_prob=bert_dropout,\n",
    ")\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          max_length=max_seq_length,\n",
    "                                          padding=padding_strategy,\n",
    "                                          truncation=truncation_strategy,\n",
    "                                          do_lower_case=do_lower_case)\n",
    "# Load the BERT model with the custom configuration\n",
    "bert_model = BertModel(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0815b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/admin/Downloads/Binary_dataset.csv\"\n",
    "data_df = pd.read_csv(data_path)\n",
    "data_df = data_df.rename(columns={'Tweet Content': 'text', 'Label': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd15764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Worst Bong ever. https://t.co/QA7R8VYppC</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what i dont like about leni robredo's platform...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ito ang tunay na survey ni VP Leni Robredo #1 ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3) BBM sued for Pork Barrel Scam\\n\\nhttps://t...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sabog din sumagot tong si Norberto Gonzales no...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text Sentiment label\n",
       "0           Worst Bong ever. https://t.co/QA7R8VYppC  Negative  Hate\n",
       "1  what i dont like about leni robredo's platform...  Negative  Hate\n",
       "2  Ito ang tunay na survey ni VP Leni Robredo #1 ...  Negative  Hate\n",
       "3  (3) BBM sued for Pork Barrel Scam\\n\\nhttps://t...  Negative  Hate\n",
       "4  Sabog din sumagot tong si Norberto Gonzales no...  Negative  Hate"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d3add86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>I took The Blind Test and my top candidates ar...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>\"True leader show up and man up.\" - VP Leni Ro...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>Leni Robredo for president cutie ðŸ¤žðŸŒ¸</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>Ako si Christian Tan, kabataan at kaisa ni Bon...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>Ate @xlykable Letâ€™s support VP Leni and Sen. K...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>Just because Aiai did not supported Leni Robre...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>â€œMga kababayan, summon the warrior in you and ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>@thekiarasworld Now I know that not all of the...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3838</th>\n",
       "      <td>Ping Lacson Ang may Plano sa bansa\\n\\n#KayPing...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3839</th>\n",
       "      <td>@dfenderwoborder Pls watch &amp;amp; share.  Ang g...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text Sentiment     label\n",
       "2560  I took The Blind Test and my top candidates ar...  Positive  Non-hate\n",
       "2561  \"True leader show up and man up.\" - VP Leni Ro...  Positive  Non-hate\n",
       "2562                Leni Robredo for president cutie ðŸ¤žðŸŒ¸  Positive  Non-hate\n",
       "2563  Ako si Christian Tan, kabataan at kaisa ni Bon...  Positive  Non-hate\n",
       "2564  Ate @xlykable Letâ€™s support VP Leni and Sen. K...  Positive  Non-hate\n",
       "...                                                 ...       ...       ...\n",
       "3835  Just because Aiai did not supported Leni Robre...  Positive  Non-hate\n",
       "3836  â€œMga kababayan, summon the warrior in you and ...  Positive  Non-hate\n",
       "3837  @thekiarasworld Now I know that not all of the...  Positive  Non-hate\n",
       "3838  Ping Lacson Ang may Plano sa bansa\\n\\n#KayPing...  Positive  Non-hate\n",
       "3839  @dfenderwoborder Pls watch &amp; share.  Ang g...  Positive  Non-hate\n",
       "\n",
       "[1280 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupedby_sentiment = data_df.groupby(data_df.Sentiment)\n",
    "data_df_positive = groupedby_sentiment.get_group(\"Positive\")\n",
    "data_df_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaa751cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Worst Bong ever. https://t.co/QA7R8VYppC</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what i dont like about leni robredo's platform...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ito ang tunay na survey ni VP Leni Robredo #1 ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3) BBM sued for Pork Barrel Scam\\n\\nhttps://t...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sabog din sumagot tong si Norberto Gonzales no...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>Headline: The ambitious presidential candidate...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>Norberto Gonzales is right, its a missed oppor...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>The audacity to call Leni Robredo \"bobo\", \" ta...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>Bongbong Marcos is a Nazi. https://t.co/gY3xHb...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>Ang humihingi ng Respeto dapat marunong din Ru...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text Sentiment label\n",
       "0              Worst Bong ever. https://t.co/QA7R8VYppC  Negative  Hate\n",
       "1     what i dont like about leni robredo's platform...  Negative  Hate\n",
       "2     Ito ang tunay na survey ni VP Leni Robredo #1 ...  Negative  Hate\n",
       "3     (3) BBM sued for Pork Barrel Scam\\n\\nhttps://t...  Negative  Hate\n",
       "4     Sabog din sumagot tong si Norberto Gonzales no...  Negative  Hate\n",
       "...                                                 ...       ...   ...\n",
       "2555  Headline: The ambitious presidential candidate...  Negative  Hate\n",
       "2556  Norberto Gonzales is right, its a missed oppor...  Negative  Hate\n",
       "2557  The audacity to call Leni Robredo \"bobo\", \" ta...  Negative  Hate\n",
       "2558  Bongbong Marcos is a Nazi. https://t.co/gY3xHb...  Negative  Hate\n",
       "2559  Ang humihingi ng Respeto dapat marunong din Ru...  Negative  Hate\n",
       "\n",
       "[2560 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_negative = groupedby_sentiment.get_group(\"Negative\")\n",
    "data_df_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d472736d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>bongbong marcos dot com</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>Grabe pala talaga yung actions ni Leni Robredo...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3842</th>\n",
       "      <td>â€œNgayong darating na halalan, ang tatanglaw sa...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>For this COMELEC debate:\\n\\nValedictorian: Len...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>Focus on the ball kakampinks\\n\\nPresident Leni...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>President Leni Robredo and Vice President Kiko...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>@jillrobredo ðŸŒºðŸŒºðŸŒº\\nthank you din kay @maraceped...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>LOOK: Presidential candidate Bongbong Marcos m...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>@itsmaxandcheese Leni Robredo for President 2022</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>LENI ROBREDO FOR PRESIDENT. https://t.co/b14K2...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text Sentiment     label\n",
       "3840                            bongbong marcos dot com   Neutral  Non-hate\n",
       "3841  Grabe pala talaga yung actions ni Leni Robredo...   Neutral  Non-hate\n",
       "3842  â€œNgayong darating na halalan, ang tatanglaw sa...   Neutral  Non-hate\n",
       "3843  For this COMELEC debate:\\n\\nValedictorian: Len...   Neutral  Non-hate\n",
       "3844  Focus on the ball kakampinks\\n\\nPresident Leni...   Neutral  Non-hate\n",
       "...                                                 ...       ...       ...\n",
       "5115  President Leni Robredo and Vice President Kiko...   Neutral  Non-hate\n",
       "5116  @jillrobredo ðŸŒºðŸŒºðŸŒº\\nthank you din kay @maraceped...   Neutral  Non-hate\n",
       "5117  LOOK: Presidential candidate Bongbong Marcos m...   Neutral  Non-hate\n",
       "5118   @itsmaxandcheese Leni Robredo for President 2022   Neutral  Non-hate\n",
       "5119  LENI ROBREDO FOR PRESIDENT. https://t.co/b14K2...   Neutral  Non-hate\n",
       "\n",
       "[1280 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_neutral = groupedby_sentiment.get_group(\"Neutral\")\n",
    "data_df_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9d20c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_16044\\2699631638.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_df_nonhate = data_df_positive.append(data_df_neutral)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_16044\\2699631638.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_df = data_df_hate.append(data_df_nonhate)\n"
     ]
    }
   ],
   "source": [
    "#binary hate non-hate\n",
    "data_df_hate = data_df_negative.sample(n = 2560, replace=True)\n",
    "\n",
    "data_df_positive = data_df_positive.sample(n = 1280, replace=True)\n",
    "data_df_neutral = data_df_neutral.sample(n = 1280, replace=True)\n",
    "\n",
    "data_df_nonhate = data_df_positive.append(data_df_neutral)\n",
    "\n",
    "data_df = data_df_hate.append(data_df_nonhate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56cefa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.drop(['Sentiment'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f1a120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>Reasons why Leni Robredo can't win this electi...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>A wave of misplaced nostalgia, historical disi...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>A dictatorâ€™s son rewrites history on TikTok in...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>@zechnasjm0815 @paterno_II DDS troll spotted. ...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>After long quiz ... \\n\\none of my friends call...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5093</th>\n",
       "      <td>In gathering massive crowds in different sorti...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>11:11 President Leni Robredo and Vice Presiden...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>Remember when Ms. Gray left an impression of b...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>Kung sino ka man na (PC) be brave to step down...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5067</th>\n",
       "      <td>Bakit si Leni? https://t.co/aDmDIQm1bd\\nBakit ...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     label\n",
       "1935  Reasons why Leni Robredo can't win this electi...      Hate\n",
       "626   A wave of misplaced nostalgia, historical disi...      Hate\n",
       "2475  A dictatorâ€™s son rewrites history on TikTok in...      Hate\n",
       "825   @zechnasjm0815 @paterno_II DDS troll spotted. ...      Hate\n",
       "1460  After long quiz ... \\n\\none of my friends call...      Hate\n",
       "...                                                 ...       ...\n",
       "5093  In gathering massive crowds in different sorti...  Non-hate\n",
       "4074  11:11 President Leni Robredo and Vice Presiden...  Non-hate\n",
       "4637  Remember when Ms. Gray left an impression of b...  Non-hate\n",
       "4961  Kung sino ka man na (PC) be brave to step down...  Non-hate\n",
       "5067  Bakit si Leni? https://t.co/aDmDIQm1bd\\nBakit ...  Non-hate\n",
       "\n",
       "[5120 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_df.to_csv('dataset.csv', index=False)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "803cceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f10c2e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1935</td>\n",
       "      <td>Reasons why Leni Robredo can't win this electi...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>626</td>\n",
       "      <td>A wave of misplaced nostalgia, historical disi...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2475</td>\n",
       "      <td>A dictatorâ€™s son rewrites history on TikTok in...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>825</td>\n",
       "      <td>@zechnasjm0815 @paterno_II DDS troll spotted. ...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1460</td>\n",
       "      <td>After long quiz ... \\n\\none of my friends call...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>5093</td>\n",
       "      <td>In gathering massive crowds in different sorti...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>4074</td>\n",
       "      <td>11:11 President Leni Robredo and Vice Presiden...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>4637</td>\n",
       "      <td>Remember when Ms. Gray left an impression of b...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>4961</td>\n",
       "      <td>Kung sino ka man na (PC) be brave to step down...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>5067</td>\n",
       "      <td>Bakit si Leni? https://t.co/aDmDIQm1bd\\nBakit ...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text     label\n",
       "0      1935  Reasons why Leni Robredo can't win this electi...      Hate\n",
       "1       626  A wave of misplaced nostalgia, historical disi...      Hate\n",
       "2      2475  A dictatorâ€™s son rewrites history on TikTok in...      Hate\n",
       "3       825  @zechnasjm0815 @paterno_II DDS troll spotted. ...      Hate\n",
       "4      1460  After long quiz ... \\n\\none of my friends call...      Hate\n",
       "...     ...                                                ...       ...\n",
       "5115   5093  In gathering massive crowds in different sorti...  Non-hate\n",
       "5116   4074  11:11 President Leni Robredo and Vice Presiden...  Non-hate\n",
       "5117   4637  Remember when Ms. Gray left an impression of b...  Non-hate\n",
       "5118   4961  Kung sino ka man na (PC) be brave to step down...  Non-hate\n",
       "5119   5067  Bakit si Leni? https://t.co/aDmDIQm1bd\\nBakit ...  Non-hate\n",
       "\n",
       "[5120 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c63582fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = \"dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b8afaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = tokens[:tokenizer.model_max_length - 2]  # Account for [CLS] and [SEP] tokens\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    return indexed_tokens\n",
    "\n",
    "filipino_stopwords = set(\n",
    "    \"\"\"\n",
    "akin\n",
    "aking\n",
    "ako\n",
    "alin\n",
    "am\n",
    "amin\n",
    "aming\n",
    "ang\n",
    "ano\n",
    "anumang\n",
    "apat\n",
    "at\n",
    "atin\n",
    "ating\n",
    "ay\n",
    "bababa\n",
    "bago\n",
    "bakit\n",
    "bawat\n",
    "bilang\n",
    "dahil\n",
    "dalawa\n",
    "dapat\n",
    "din\n",
    "dito\n",
    "doon\n",
    "gagawin\n",
    "gayunman\n",
    "ginagawa\n",
    "ginawa\n",
    "ginawang\n",
    "gumawa\n",
    "gusto\n",
    "habang\n",
    "hanggang\n",
    "hindi\n",
    "huwag\n",
    "iba\n",
    "ibaba\n",
    "ibabaw\n",
    "ibig\n",
    "ikaw\n",
    "ilagay\n",
    "ilalim\n",
    "ilan\n",
    "inyong\n",
    "isa\n",
    "isang\n",
    "itaas\n",
    "ito\n",
    "iyo\n",
    "iyon\n",
    "iyong\n",
    "ka\n",
    "kahit\n",
    "kailangan\n",
    "kailanman\n",
    "kami\n",
    "kanila\n",
    "kanilang\n",
    "kanino\n",
    "kanya\n",
    "kanyang\n",
    "kapag\n",
    "kapwa\n",
    "karamihan\n",
    "katiyakan\n",
    "katulad\n",
    "kaya\n",
    "kaysa\n",
    "ko\n",
    "kong\n",
    "kulang\n",
    "kumuha\n",
    "kung\n",
    "laban\n",
    "lahat\n",
    "lamang\n",
    "likod\n",
    "lima\n",
    "maaari\n",
    "maaaring\n",
    "maging\n",
    "mahusay\n",
    "makita\n",
    "marami\n",
    "marapat\n",
    "masyado\n",
    "may\n",
    "mayroon\n",
    "mga\n",
    "minsan\n",
    "mismo\n",
    "mula\n",
    "muli\n",
    "na\n",
    "nabanggit\n",
    "naging\n",
    "nagkaroon\n",
    "nais\n",
    "nakita\n",
    "namin\n",
    "napaka\n",
    "narito\n",
    "nasaan\n",
    "ng\n",
    "ngayon\n",
    "ni\n",
    "nila\n",
    "nilang\n",
    "nito\n",
    "niya\n",
    "niyang\n",
    "noon\n",
    "o\n",
    "pa\n",
    "paano\n",
    "pababa\n",
    "paggawa\n",
    "pagitan\n",
    "pagkakaroon\n",
    "pagkatapos\n",
    "palabas\n",
    "pamamagitan\n",
    "panahon\n",
    "pangalawa\n",
    "para\n",
    "paraan\n",
    "pareho\n",
    "pataas\n",
    "pero\n",
    "pumunta\n",
    "pumupunta\n",
    "sa\n",
    "saan\n",
    "sabi\n",
    "sabihin\n",
    "sarili\n",
    "sila\n",
    "sino\n",
    "siya\n",
    "tatlo\n",
    "tayo\n",
    "tulad\n",
    "tungkol\n",
    "una\n",
    "walang\n",
    "\"\"\".split()\n",
    ")\n",
    "\n",
    "# Date De-Identification\n",
    "def remove_mentions(text):\n",
    "    mention_pattern = re.compile(r'@\\w+')\n",
    "    \n",
    "    # Use re.sub to remove mentions\n",
    "    cleaned_text = mention_pattern.sub('', text)\n",
    "    \n",
    "    # Remove extra spaces and strip leading/trailing spaces\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# URL Removal\n",
    "def remove_url(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    \n",
    "    # Use re.sub to remove URLs\n",
    "    cleaned_text = url_pattern.sub('', text)\n",
    "    \n",
    "    # Remove extra spaces and strip leading/trailing spaces\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Special Characters Removal\n",
    "def remove_special_characters(text):\n",
    "    text = emoji.replace_emoji(text, replace=\"[emoji]\")\n",
    "    \n",
    "    # Split the text into words\n",
    "    words = text.split(\" \")\n",
    "    \n",
    "    # Initialize an empty string to store the cleaned text\n",
    "    cleaned_text = \"\"\n",
    "    \n",
    "    # Iterate through each word\n",
    "    for word in words:\n",
    "        # Check if the word contains only special characters or \"[emoji]\"\n",
    "        if not (re.match(r\"^[_\\W]+$\", word) or \"[emoji]\" in word):\n",
    "            if len(cleaned_text) == 0:\n",
    "                cleaned_text = f\"{word}\"\n",
    "            else:\n",
    "                cleaned_text = f\"{cleaned_text} {word}\"\n",
    "                \n",
    "    # Remove diacritics\n",
    "    text_no_diacritics = unidecode.unidecode(cleaned_text)\n",
    "\n",
    "    # Split the text into words\n",
    "    sentence = text_no_diacritics.split(\" \")\n",
    "    output = \"\"\n",
    "\n",
    "    # Remove special characters and numerics\n",
    "    for part in sentence:\n",
    "        part = re.sub(\"[^A-Za-z ]+$\", \"\", part)\n",
    "        part = re.sub(\"^[^A-Za-z #]+\", \"\", part)\n",
    "        if not (len(part) <= 1 or re.match(r\"[^a-zA-Z#]\", part)):\n",
    "            if len(output) == 0:\n",
    "                output = f\"{part}\"\n",
    "            else:\n",
    "                output = f\"{output} {part}\"\n",
    "\n",
    "    # Remove extra spaces and strip leading/trailing spaces\n",
    "    cleaned_text = ' '.join(output.split())\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Remove English Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "# Remove English Stop Words\n",
    "def remove_english_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Remove extra spaces and strip leading/trailing spaces\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Remove Filipino Stop Words\n",
    "def remove_filipino_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in filipino_stopwords]\n",
    "    \n",
    "    # Remove extra spaces and strip leading/trailing spaces\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "  \n",
    "    return cleaned_text\n",
    "\n",
    "# Candidate Name Removal\n",
    "def remove_candidate_names(text):\n",
    "    candidatelist = \"leni robredo bongbong marcos isko moreno domagoso manny pacman pacquiao ping lacson ernie abella leody de guzman norberto gonzales jose montemayor jr faisal mangondato\"\n",
    "    candidatelist = candidatelist.split()\n",
    "    candidate_pattern = re.compile(r'\\b(?:' + '|'.join(map(re.escape, candidatelist)) + r')\\b', re.IGNORECASE)\n",
    "    \n",
    "    # Use re.sub to remove candidate names\n",
    "    cleaned_text = candidate_pattern.sub('', text)\n",
    "    \n",
    "    # Remove extra spaces and strip leading/trailing spaces\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "        \n",
    "    return cleaned_text\n",
    "\n",
    "# Hashtag Removal\n",
    "def remove_hashtags(text):\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Initialize an empty list to store cleaned words\n",
    "    cleaned_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Check if the word is a hashtag (starts with #)\n",
    "        if not word.startswith('#'):\n",
    "            cleaned_words.append(word)\n",
    "    \n",
    "    # Join the cleaned words into a single string\n",
    "    cleaned_text = ' '.join(cleaned_words)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Hashtag Removal\n",
    "def remove_hashtag_symbols(text):\n",
    "    # Use regular expression to remove \"#\" before words\n",
    "    cleaned_text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    \n",
    "    # Remove extra spaces and strip leading/trailing spaces\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b3226a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad02bb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  Reasons why Leni Robredo can't win this election: 1.She's yellow 2.Kakampinks attitude 3.RAPPLER Basically negatrons who are backing her candidacy causes major turn off sa mga voters. https://t.co/vGaLIO0pMP \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  A wave of misplaced nostalgia, historical disinformation, and an incredible tale about gold bars could get dictator Marcosâ€™ son Bongbong elected Philippine president. My latest for . https://t.co/8uCmkT2aOr \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  A dictatorâ€™s son rewrites history on TikTok in his bid to become the Philippinesâ€™ next President https://t.co/U4zinxCsy2 Â¿Otra vez arroz? \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  DDS troll spotted. Tanga ka siguro nung nag aaral ka. Or wala ka pinag aralan? Haha. Magbasa ka. Mas Madami pa ginawa Leni Robredo kesa sa iba kahit di xa binigyan masyado ng budget ng #Dutae administration. Yang Sara nyo, pupunta sa inodoro. \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  After long quiz ... one of my friends called. : Ang presidente Leni Robredo, Bise Presidente Kiko Pangilinan Me: Lessgo! Wala kaming pake sa inyong presidente basta kame BBM-Sara Duterte ... HAHA Aliw talaga ðŸ¤£ Oh see? 'Di naman need lagi mag-away jusq \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  MarcosJr. duwag. Ayaw umattend ng mga debate dahil hindi kayang ipagtanggol ang sarili at pamilya nya. Kung ang sarili at pamilya nya nga ay hindi nya kayang ipagtanggol at panindigan, ang sambayanang Pilipino pa kaya? Gising Pilipinas!!! LENI ROBREDO FOR THE WIN!!! ðŸ™ðŸ’—ðŸ’—ðŸ’—ðŸ™ \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  The three eldest of Leni Lutang Robredo ðŸ¤£ \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  ISANG ILOCANA NA MAS MADAMI PANG CREDENTIALS KESA KAY BONGBONG MARCOS!! https://t.co/qNY8fzG6Zd \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  MarcosJr. duwag. Ayaw umattend ng mga debate dahil hindi kayang ipagtanggol ang sarili at pamilya nya. Kung ang sarili at pamilya nya nga ay hindi nya kayang ipagtanggol at panindigan, ang sambayanang Pilipino pa kaya? Gising Pilipinas!!! LENI ROBREDO FOR THE WIN!!! ðŸ™ðŸ’—ðŸ’—ðŸ’—ðŸ™ \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Leni Robredo, Best candidate Worst supporters https://t.co/AxopYAT9Ez \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data De-Identification\n",
    "data_df['text'] = data_df['text'].apply(remove_mentions)\n",
    "\n",
    "for i in range(10):\n",
    "    text = data_df[\"text\"][i]\n",
    "    label = data_df[\"label\"][i]\n",
    "\n",
    "    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1899b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  Reasons why Leni Robredo can't win this election: 1.She's yellow 2.Kakampinks attitude 3.RAPPLER Basically negatrons who are backing her candidacy causes major turn off sa mga voters. \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  A wave of misplaced nostalgia, historical disinformation, and an incredible tale about gold bars could get dictator Marcosâ€™ son Bongbong elected Philippine president. My latest for . \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  A dictatorâ€™s son rewrites history on TikTok in his bid to become the Philippinesâ€™ next President Â¿Otra vez arroz? \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  DDS troll spotted. Tanga ka siguro nung nag aaral ka. Or wala ka pinag aralan? Haha. Magbasa ka. Mas Madami pa ginawa Leni Robredo kesa sa iba kahit di xa binigyan masyado ng budget ng #Dutae administration. Yang Sara nyo, pupunta sa inodoro. \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  After long quiz ... one of my friends called. : Ang presidente Leni Robredo, Bise Presidente Kiko Pangilinan Me: Lessgo! Wala kaming pake sa inyong presidente basta kame BBM-Sara Duterte ... HAHA Aliw talaga ðŸ¤£ Oh see? 'Di naman need lagi mag-away jusq \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  MarcosJr. duwag. Ayaw umattend ng mga debate dahil hindi kayang ipagtanggol ang sarili at pamilya nya. Kung ang sarili at pamilya nya nga ay hindi nya kayang ipagtanggol at panindigan, ang sambayanang Pilipino pa kaya? Gising Pilipinas!!! LENI ROBREDO FOR THE WIN!!! ðŸ™ðŸ’—ðŸ’—ðŸ’—ðŸ™ \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  The three eldest of Leni Lutang Robredo ðŸ¤£ \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  ISANG ILOCANA NA MAS MADAMI PANG CREDENTIALS KESA KAY BONGBONG MARCOS!! \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  MarcosJr. duwag. Ayaw umattend ng mga debate dahil hindi kayang ipagtanggol ang sarili at pamilya nya. Kung ang sarili at pamilya nya nga ay hindi nya kayang ipagtanggol at panindigan, ang sambayanang Pilipino pa kaya? Gising Pilipinas!!! LENI ROBREDO FOR THE WIN!!! ðŸ™ðŸ’—ðŸ’—ðŸ’—ðŸ™ \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Leni Robredo, Best candidate Worst supporters \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# URL Removal\n",
    "data_df['text'] = data_df['text'].apply(remove_url)\n",
    "\n",
    "for i in range(10):\n",
    "    text = data_df[\"text\"][i]\n",
    "    label = data_df[\"label\"][i]\n",
    "\n",
    "    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50e8dc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  Reasons why Leni Robredo can't win this election She's yellow Kakampinks attitude RAPPLER Basically negatrons who are backing her candidacy causes major turn off sa mga voters \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  wave of misplaced nostalgia historical disinformation and an incredible tale about gold bars could get dictator Marcos son Bongbong elected Philippine president My latest for \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  dictator's son rewrites history on TikTok in his bid to become the Philippines next President Otra vez arroz \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  DDS troll spotted Tanga ka siguro nung nag aaral ka Or wala ka pinag aralan Haha Magbasa ka Mas Madami pa ginawa Leni Robredo kesa sa iba kahit di xa binigyan masyado ng budget ng #Dutae administration Yang Sara nyo pupunta sa inodoro \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  After long quiz one of my friends called Ang presidente Leni Robredo Bise Presidente Kiko Pangilinan Me Lessgo Wala kaming pake sa inyong presidente basta kame BBM-Sara Duterte HAHA Aliw talaga Oh see Di naman need lagi mag-away jusq \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  MarcosJr duwag Ayaw umattend ng mga debate dahil hindi kayang ipagtanggol ang sarili at pamilya nya Kung ang sarili at pamilya nya nga ay hindi nya kayang ipagtanggol at panindigan ang sambayanang Pilipino pa kaya Gising Pilipinas LENI ROBREDO FOR THE WIN \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  The three eldest of Leni Lutang Robredo \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  ISANG ILOCANA NA MAS MADAMI PANG CREDENTIALS KESA KAY BONGBONG MARCOS \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  MarcosJr duwag Ayaw umattend ng mga debate dahil hindi kayang ipagtanggol ang sarili at pamilya nya Kung ang sarili at pamilya nya nga ay hindi nya kayang ipagtanggol at panindigan ang sambayanang Pilipino pa kaya Gising Pilipinas LENI ROBREDO FOR THE WIN \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Leni Robredo Best candidate Worst supporters \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Special Characters Removal\n",
    "data_df['text'] = data_df['text'].apply(remove_special_characters)\n",
    "\n",
    "for i in range(10):\n",
    "    text = data_df[\"text\"][i]\n",
    "    label = data_df[\"label\"][i]\n",
    "\n",
    "    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7b2db5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  reasons why leni robredo can't win this election she's yellow kakampinks attitude rappler basically negatrons who are backing her candidacy causes major turn off sa mga voters \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  wave of misplaced nostalgia historical disinformation and an incredible tale about gold bars could get dictator marcos son bongbong elected philippine president my latest for \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  dictator's son rewrites history on tiktok in his bid to become the philippines next president otra vez arroz \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  dds troll spotted tanga ka siguro nung nag aaral ka or wala ka pinag aralan haha magbasa ka mas madami pa ginawa leni robredo kesa sa iba kahit di xa binigyan masyado ng budget ng #dutae administration yang sara nyo pupunta sa inodoro \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  after long quiz one of my friends called ang presidente leni robredo bise presidente kiko pangilinan me lessgo wala kaming pake sa inyong presidente basta kame bbm-sara duterte haha aliw talaga oh see di naman need lagi mag-away jusq \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  marcosjr duwag ayaw umattend ng mga debate dahil hindi kayang ipagtanggol ang sarili at pamilya nya kung ang sarili at pamilya nya nga ay hindi nya kayang ipagtanggol at panindigan ang sambayanang pilipino pa kaya gising pilipinas leni robredo for the win \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  the three eldest of leni lutang robredo \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  isang ilocana na mas madami pang credentials kesa kay bongbong marcos \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  marcosjr duwag ayaw umattend ng mga debate dahil hindi kayang ipagtanggol ang sarili at pamilya nya kung ang sarili at pamilya nya nga ay hindi nya kayang ipagtanggol at panindigan ang sambayanang pilipino pa kaya gising pilipinas leni robredo for the win \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  leni robredo best candidate worst supporters \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lowercase\n",
    "data_df['text'] = data_df['text'].str.lower()\n",
    "\n",
    "for i in range(10):\n",
    "    text = data_df[\"text\"][i]\n",
    "    label = data_df[\"label\"][i]\n",
    "\n",
    "    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb92a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove English Stop Words\n",
    "# data_df['text'] = data_df['text'].apply(remove_english_stopwords)\n",
    "\n",
    "# for i in range(10):\n",
    "#    text = data_df[\"text\"][i]\n",
    "#    label = data_df[\"label\"][i]\n",
    "\n",
    "#    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86e9cf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Filipino Stop Words\n",
    "# data_df['text'] = data_df['text'].apply(remove_filipino_stopwords)\n",
    "\n",
    "# for i in range(10):\n",
    "#    text = data_df[\"text\"][i]\n",
    "#    label = data_df[\"label\"][i]\n",
    "\n",
    "#    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f586bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Candidate Names\n",
    "# data_df['text'] = data_df['text'].apply(remove_candidate_names)\n",
    "\n",
    "# for i in range(10):\n",
    "    # text = data_df[\"text\"][i]\n",
    "    # label = data_df[\"label\"][i]\n",
    "\n",
    "    # print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2e98e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Hashtags\n",
    "# data_df['text'] = data_df['text'].apply(remove_hashtags)\n",
    "\n",
    "# for i in range(10):\n",
    "#    text = data_df[\"text\"][i]\n",
    "#    label = data_df[\"label\"][i]\n",
    "\n",
    "#    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7eb4c5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  reasons why leni robredo can't win this election she's yellow kakampinks attitude rappler basically negatrons who are backing her candidacy causes major turn off sa mga voters \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  wave of misplaced nostalgia historical disinformation and an incredible tale about gold bars could get dictator marcos son bongbong elected philippine president my latest for \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  dictator's son rewrites history on tiktok in his bid to become the philippines next president otra vez arroz \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  dds troll spotted tanga ka siguro nung nag aaral ka or wala ka pinag aralan haha magbasa ka mas madami pa ginawa leni robredo kesa sa iba kahit di xa binigyan masyado ng budget ng dutae administration yang sara nyo pupunta sa inodoro \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  after long quiz one of my friends called ang presidente leni robredo bise presidente kiko pangilinan me lessgo wala kaming pake sa inyong presidente basta kame bbm-sara duterte haha aliw talaga oh see di naman need lagi mag-away jusq \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  marcosjr duwag ayaw umattend ng mga debate dahil hindi kayang ipagtanggol ang sarili at pamilya nya kung ang sarili at pamilya nya nga ay hindi nya kayang ipagtanggol at panindigan ang sambayanang pilipino pa kaya gising pilipinas leni robredo for the win \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  the three eldest of leni lutang robredo \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  isang ilocana na mas madami pang credentials kesa kay bongbong marcos \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  marcosjr duwag ayaw umattend ng mga debate dahil hindi kayang ipagtanggol ang sarili at pamilya nya kung ang sarili at pamilya nya nga ay hindi nya kayang ipagtanggol at panindigan ang sambayanang pilipino pa kaya gising pilipinas leni robredo for the win \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  leni robredo best candidate worst supporters \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove Hashtag Symbols\n",
    "data_df['text'] = data_df['text'].apply(remove_hashtag_symbols)\n",
    "\n",
    "for i in range(10):\n",
    "    text = data_df[\"text\"][i]\n",
    "    label = data_df[\"label\"][i]\n",
    "\n",
    "    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63b091cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv('binary11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7cc88bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1935</td>\n",
       "      <td>reasons why leni robredo can't win this electi...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>626</td>\n",
       "      <td>wave of misplaced nostalgia historical disinfo...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2475</td>\n",
       "      <td>dictator's son rewrites history on tiktok in h...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>825</td>\n",
       "      <td>dds troll spotted tanga ka siguro nung nag aar...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1460</td>\n",
       "      <td>after long quiz one of my friends called ang p...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>5093</td>\n",
       "      <td>in gathering massive crowds in different sorti...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>4074</td>\n",
       "      <td>president leni robredo and vice president kiko...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>4637</td>\n",
       "      <td>remember when ms gray left an impression of be...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>4961</td>\n",
       "      <td>kung sino ka man na pc be brave to step down a...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>5067</td>\n",
       "      <td>bakit si leni bakit si kiko ipanaloparasalahat...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text     label\n",
       "0      1935  reasons why leni robredo can't win this electi...      Hate\n",
       "1       626  wave of misplaced nostalgia historical disinfo...      Hate\n",
       "2      2475  dictator's son rewrites history on tiktok in h...      Hate\n",
       "3       825  dds troll spotted tanga ka siguro nung nag aar...      Hate\n",
       "4      1460  after long quiz one of my friends called ang p...      Hate\n",
       "...     ...                                                ...       ...\n",
       "5115   5093  in gathering massive crowds in different sorti...  Non-hate\n",
       "5116   4074  president leni robredo and vice president kiko...  Non-hate\n",
       "5117   4637  remember when ms gray left an impression of be...  Non-hate\n",
       "5118   4961  kung sino ka man na pc be brave to step down a...  Non-hate\n",
       "5119   5067  bakit si leni bakit si kiko ipanaloparasalahat...  Non-hate\n",
       "\n",
       "[5120 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "364e034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['text'] = data_df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f32559d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1935</td>\n",
       "      <td>[4436, 2339, 18798, 2072, 6487, 23417, 2064, 1...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>626</td>\n",
       "      <td>[4400, 1997, 28616, 22829, 26968, 3439, 4487, ...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2475</td>\n",
       "      <td>[21237, 1005, 1055, 2365, 2128, 26373, 2015, 2...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>825</td>\n",
       "      <td>[20315, 2015, 18792, 7282, 9745, 2050, 10556, ...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1460</td>\n",
       "      <td>[2044, 2146, 19461, 2028, 1997, 2026, 2814, 21...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>5093</td>\n",
       "      <td>[1999, 7215, 5294, 12783, 1999, 2367, 4066, 31...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>4074</td>\n",
       "      <td>[2343, 18798, 2072, 6487, 23417, 1998, 3580, 2...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>4637</td>\n",
       "      <td>[3342, 2043, 5796, 3897, 2187, 2019, 8605, 199...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>4961</td>\n",
       "      <td>[18577, 19432, 10556, 2158, 6583, 7473, 2022, ...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>5067</td>\n",
       "      <td>[8670, 23615, 9033, 18798, 2072, 8670, 23615, ...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text     label\n",
       "0      1935  [4436, 2339, 18798, 2072, 6487, 23417, 2064, 1...      Hate\n",
       "1       626  [4400, 1997, 28616, 22829, 26968, 3439, 4487, ...      Hate\n",
       "2      2475  [21237, 1005, 1055, 2365, 2128, 26373, 2015, 2...      Hate\n",
       "3       825  [20315, 2015, 18792, 7282, 9745, 2050, 10556, ...      Hate\n",
       "4      1460  [2044, 2146, 19461, 2028, 1997, 2026, 2814, 21...      Hate\n",
       "...     ...                                                ...       ...\n",
       "5115   5093  [1999, 7215, 5294, 12783, 1999, 2367, 4066, 31...  Non-hate\n",
       "5116   4074  [2343, 18798, 2072, 6487, 23417, 1998, 3580, 2...  Non-hate\n",
       "5117   4637  [3342, 2043, 5796, 3897, 2187, 2019, 8605, 199...  Non-hate\n",
       "5118   4961  [18577, 19432, 10556, 2158, 6583, 7473, 2022, ...  Non-hate\n",
       "5119   5067  [8670, 23615, 9033, 18798, 2072, 8670, 23615, ...  Non-hate\n",
       "\n",
       "[5120 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "274bc204",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size=0.1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3706e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_dropout = nn.Dropout(dropout) \n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=256, kernel_size=2, padding='same')\n",
    "        self.pool1 = nn.MaxPool1d(2, 2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=256, out_channels=64, kernel_size=4, padding='same')\n",
    "        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        x = embedded.permute(0, 2, 1)  # Change the dimensions for convolution\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.global_pooling(x).squeeze(2)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9d73f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up iterators\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a9a6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, max_seq_length):\n",
    "        self.data = dataframe\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['text']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "\n",
    "        # Padding and conversion to tensor\n",
    "        padded_text = torch.tensor(text[:self.max_seq_length] + [0] * (self.max_seq_length - len(text)))\n",
    "        return padded_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2db27b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_df, 1000)\n",
    "test_dataset = TextDataset(test_df, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "782d32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_iterator = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce1934a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model hyperparameters\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "EMBEDDING_DIM = 768\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3, 4, 5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# CNN Hyperparameters\n",
    "hidden_dim = 100\n",
    "n_conv_layers = 1\n",
    "kernel_sizes = [2, 3, 4]\n",
    "activation = nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "657020f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CNN model\n",
    "model = CNN(VOCAB_SIZE, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
    "#Initialize CNN model\n",
    "# model = CNN(VOCAB_SIZE, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, hidden_dim, n_conv_layers, kernel_sizes, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6896c237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.9, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize BERT model (for embedding extraction)\n",
    "bert_model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d06a906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, token in enumerate(tokenizer.get_vocab()):\n",
    "        token_id = tokenizer.convert_tokens_to_ids(token)\n",
    "        token_embedding = bert_model.embeddings.word_embeddings.weight[token_id]\n",
    "        model.embedding.weight[i].data.copy_(token_embedding)\n",
    "\n",
    "bert_parameters = []\n",
    "for layer in bert_model.encoder.layer:\n",
    "    bert_parameters.extend(layer.parameters())\n",
    "\n",
    "# Create AdamW optimizer with custom hyperparameters for BERT embeddings\n",
    "bert_learning_rate = 2e-4  # Adjust as needed\n",
    "bert_optimizer = optim.AdamW(bert_parameters, lr=bert_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc3596cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1935</td>\n",
       "      <td>[4436, 2339, 18798, 2072, 6487, 23417, 2064, 1...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>626</td>\n",
       "      <td>[4400, 1997, 28616, 22829, 26968, 3439, 4487, ...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2475</td>\n",
       "      <td>[21237, 1005, 1055, 2365, 2128, 26373, 2015, 2...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>825</td>\n",
       "      <td>[20315, 2015, 18792, 7282, 9745, 2050, 10556, ...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1460</td>\n",
       "      <td>[2044, 2146, 19461, 2028, 1997, 2026, 2814, 21...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>5093</td>\n",
       "      <td>[1999, 7215, 5294, 12783, 1999, 2367, 4066, 31...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>4074</td>\n",
       "      <td>[2343, 18798, 2072, 6487, 23417, 1998, 3580, 2...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>4637</td>\n",
       "      <td>[3342, 2043, 5796, 3897, 2187, 2019, 8605, 199...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>4961</td>\n",
       "      <td>[18577, 19432, 10556, 2158, 6583, 7473, 2022, ...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>5067</td>\n",
       "      <td>[8670, 23615, 9033, 18798, 2072, 8670, 23615, ...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text     label\n",
       "0      1935  [4436, 2339, 18798, 2072, 6487, 23417, 2064, 1...      Hate\n",
       "1       626  [4400, 1997, 28616, 22829, 26968, 3439, 4487, ...      Hate\n",
       "2      2475  [21237, 1005, 1055, 2365, 2128, 26373, 2015, 2...      Hate\n",
       "3       825  [20315, 2015, 18792, 7282, 9745, 2050, 10556, ...      Hate\n",
       "4      1460  [2044, 2146, 19461, 2028, 1997, 2026, 2814, 21...      Hate\n",
       "...     ...                                                ...       ...\n",
       "5115   5093  [1999, 7215, 5294, 12783, 1999, 2367, 4066, 31...  Non-hate\n",
       "5116   4074  [2343, 18798, 2072, 6487, 23417, 1998, 3580, 2...  Non-hate\n",
       "5117   4637  [3342, 2043, 5796, 3897, 2187, 2019, 8605, 199...  Non-hate\n",
       "5118   4961  [18577, 19432, 10556, 2158, 6583, 7473, 2022, ...  Non-hate\n",
       "5119   5067  [8670, 23615, 9033, 18798, 2072, 8670, 23615, ...  Non-hate\n",
       "\n",
       "[5120 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02c4f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(model.parameters())\n",
    "# Your custom hyperparameters\n",
    "learning_rate = 0.001\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "epsilon = 1e-08\n",
    "weight_decay = 0.0\n",
    "\n",
    "# Create Adam optimizer with custom hyperparameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta_1, beta_2), eps=epsilon, weight_decay=weight_decay)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e33b7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train(model, iterator):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for text_batch, label_batch in iterator:\n",
    "        # Extract text sequences from the text_batch tensor\n",
    "        texts = text_batch\n",
    "        \n",
    "        # Extract and process labels\n",
    "        labels = [1 if label == 'Hate' else 0 for label in label_batch]  # Example conversion\n",
    "        \n",
    "        texts = texts.to(device)  # Move to device if needed\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).to(device)  # Convert to tensor\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(texts).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "# Evaluate function\n",
    "def evaluate(model, iterator):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []  # Declare the true_labels list\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch in iterator:\n",
    "            texts = text_batch  # Extract text sequences\n",
    "            labels = [1 if label == 'Hate' else 0 for label in label_batch]  # Example conversion\n",
    "            \n",
    "            texts = texts.to(device)  # Move to device\n",
    "            labels = torch.tensor(labels, dtype=torch.float32).to(device)  # Convert to tensor\n",
    "            \n",
    "            predictions = model(texts).squeeze(1)\n",
    "            loss = criterion(predictions, labels)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            predicted_labels.extend(torch.round(torch.sigmoid(predictions)).cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy, f1, precision, recall\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    \n",
    "    return epoch_loss / len(iterator), accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.558\n",
      "\tTest Loss: 0.414\n",
      "\tAccuracy: 0.8223 | F1-Score: 0.8312\n",
      "\tPrecision: 0.7805 | Recall: 0.8889\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.292\n",
      "\tTest Loss: 0.315\n",
      "\tAccuracy: 0.8750 | F1-Score: 0.8764\n",
      "\tPrecision: 0.8534 | Recall: 0.9008\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.170\n",
      "\tTest Loss: 0.268\n",
      "\tAccuracy: 0.9023 | F1-Score: 0.8992\n",
      "\tPrecision: 0.9139 | Recall: 0.8849\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.095\n",
      "\tTest Loss: 0.345\n",
      "\tAccuracy: 0.8906 | F1-Score: 0.8923\n",
      "\tPrecision: 0.8657 | Recall: 0.9206\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.070\n",
      "\tTest Loss: 0.335\n",
      "\tAccuracy: 0.8965 | F1-Score: 0.8934\n",
      "\tPrecision: 0.9061 | Recall: 0.8810\n",
      "Epoch: 06\n",
      "\tTrain Loss: 0.046\n",
      "\tTest Loss: 0.369\n",
      "\tAccuracy: 0.9043 | F1-Score: 0.9034\n",
      "\tPrecision: 0.8980 | Recall: 0.9087\n",
      "Epoch: 07\n",
      "\tTrain Loss: 0.038\n",
      "\tTest Loss: 0.377\n",
      "\tAccuracy: 0.9102 | F1-Score: 0.9094\n",
      "\tPrecision: 0.9023 | Recall: 0.9167\n",
      "Epoch: 08\n",
      "\tTrain Loss: 0.024\n",
      "\tTest Loss: 0.411\n",
      "\tAccuracy: 0.9023 | F1-Score: 0.9000\n",
      "\tPrecision: 0.9073 | Recall: 0.8929\n",
      "Epoch: 09\n",
      "\tTrain Loss: 0.024\n",
      "\tTest Loss: 0.426\n",
      "\tAccuracy: 0.9004 | F1-Score: 0.8974\n",
      "\tPrecision: 0.9102 | Recall: 0.8849\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_iterator)\n",
    "    test_loss, accuracy, f1, precision, recall = evaluate(model, test_iterator)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\tTest Loss: {test_loss:.3f}')\n",
    "    print(f'\\tAccuracy: {accuracy:.4f} | F1-Score: {f1:.4f}')\n",
    "    print(f'\\tPrecision: {precision:.4f} | Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee1e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dece720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da131100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
