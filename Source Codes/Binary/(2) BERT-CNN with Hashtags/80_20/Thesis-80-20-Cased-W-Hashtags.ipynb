{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5486b8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mark Gabriel\n",
      "[nltk_data]     Ortiz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from transformers import AdamW\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import csv\n",
    "import re\n",
    "import validators\n",
    "import emoji\n",
    "import unidecode\n",
    "import nltk\n",
    "import pickle\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6954a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "SEED = 1235\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# BERT Hyperparameters (ADDITION)\n",
    "n_bert_layers = 16  # Assuming the base model has 12 layers\n",
    "bert_lr = 0.001\n",
    "pooling_strategy = 'cls'  # Options: 'cls', 'mean', 'max'\n",
    "bert_hidden_size = 768  # Adjust based on your BERT model\n",
    "max_seq_length = 128\n",
    "fine_tune_strategy = 'last_layer'  # Options: 'full', 'last_layer'\n",
    "bert_dropout = 0.9  # Adjust based on BERT model specifications\n",
    "\n",
    "max_seq_length = 128  # This should match the max_seq_length used in BERT model\n",
    "padding_strategy = 'max_length'  # Options: 'max_length', 'do_not_pad', 'longest'\n",
    "truncation_strategy = 'longest_first'  # Options: 'longest_first', 'only_first', 'only_second'\n",
    "do_lower_case = True  # Set to False if using a cased model\n",
    "\n",
    "config = BertConfig(\n",
    "    num_hidden_layers=n_bert_layers,\n",
    "    hidden_size=bert_hidden_size,\n",
    "    num_attention_heads=12,  # Assuming 12 attention heads\n",
    "    intermediate_size=4 * bert_hidden_size,  # Default value in BERT\n",
    "    hidden_dropout_prob=bert_dropout,\n",
    "    attention_probs_dropout_prob=bert_dropout,\n",
    ")\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', \n",
    "                                          max_length=max_seq_length,\n",
    "                                          padding=padding_strategy,\n",
    "                                          truncation=truncation_strategy,\n",
    "                                          do_lower_case=do_lower_case)\n",
    "# Load the BERT model with the custom configuration\n",
    "bert_model = BertModel(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0815b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'dataset.csv'\n",
    "data_df = pd.read_csv(data_path)\n",
    "data_df = data_df.rename(columns={'Tweet Content': 'text', 'Label': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd15764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KULANG ATA SA TULOG SI NORBERTO GONZALES HAHAH...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hirosii's argument screams misogyny not valid ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is the better vote? Bongbong #marcos, who ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@skzoowifey hindi siya ang tatay niya bc from ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Pontifex @LaityFamilyLife Bongbong Marcos,Sar...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text Sentiment label\n",
       "0  KULANG ATA SA TULOG SI NORBERTO GONZALES HAHAH...  Negative  Hate\n",
       "1  Hirosii's argument screams misogyny not valid ...  Negative  Hate\n",
       "2  Who is the better vote? Bongbong #marcos, who ...  Negative  Hate\n",
       "3  @skzoowifey hindi siya ang tatay niya bc from ...  Negative  Hate\n",
       "4  @Pontifex @LaityFamilyLife Bongbong Marcos,Sar...  Negative  Hate"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d3add86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>It's just so fitting for Leni Robredo, as an h...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>The Solution.\\n\\n* Leni Robredo - Philippines ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>@kikopangilinan @donny @bellemariano02 So prou...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>Ako si Bernard isang guro,nakiki-isa sa pagsup...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>@DonKissPlatum Para sa Bayan, Para sa Pagbabag...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>@GelSantosRelos @lenirobredo @cnnphilippines i...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>Wala akong duda na sa ating sama-samang pagkil...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>The most qualified president\\nPing Lacson lang...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>\"Sa Gobyernong Tapat, Angat Buhay Lahat! At si...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>Good Morning! Let's manifest sa universe ang p...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text Sentiment     label\n",
       "2400  It's just so fitting for Leni Robredo, as an h...  Positive  Non-hate\n",
       "2401  The Solution.\\n\\n* Leni Robredo - Philippines ...  Positive  Non-hate\n",
       "2402  @kikopangilinan @donny @bellemariano02 So prou...  Positive  Non-hate\n",
       "2403  Ako si Bernard isang guro,nakiki-isa sa pagsup...  Positive  Non-hate\n",
       "2404  @DonKissPlatum Para sa Bayan, Para sa Pagbabag...  Positive  Non-hate\n",
       "...                                                 ...       ...       ...\n",
       "3595  @GelSantosRelos @lenirobredo @cnnphilippines i...  Positive  Non-hate\n",
       "3596  Wala akong duda na sa ating sama-samang pagkil...  Positive  Non-hate\n",
       "3597  The most qualified president\\nPing Lacson lang...  Positive  Non-hate\n",
       "3598  \"Sa Gobyernong Tapat, Angat Buhay Lahat! At si...  Positive  Non-hate\n",
       "3599  Good Morning! Let's manifest sa universe ang p...  Positive  Non-hate\n",
       "\n",
       "[1200 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupedby_sentiment = data_df.groupby(data_df.Sentiment)\n",
    "data_df_positive = groupedby_sentiment.get_group(\"Positive\")\n",
    "data_df_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaa751cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KULANG ATA SA TULOG SI NORBERTO GONZALES HAHAH...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hirosii's argument screams misogyny not valid ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is the better vote? Bongbong #marcos, who ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@skzoowifey hindi siya ang tatay niya bc from ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Pontifex @LaityFamilyLife Bongbong Marcos,Sar...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>Absent for today‚Äôs videyow:\\n1. Bongbong Marco...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>@DisguisedPost @_Nathalieperona Mawalang galan...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>Get ready for 'BongBong' Marcos!\\n\\nHa, what a...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>Sabi ng iba bobo daw si Leni. Bobo pa siya sa ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>If ever (wag naman sana) manalo si bongbong, i...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text Sentiment label\n",
       "0     KULANG ATA SA TULOG SI NORBERTO GONZALES HAHAH...  Negative  Hate\n",
       "1     Hirosii's argument screams misogyny not valid ...  Negative  Hate\n",
       "2     Who is the better vote? Bongbong #marcos, who ...  Negative  Hate\n",
       "3     @skzoowifey hindi siya ang tatay niya bc from ...  Negative  Hate\n",
       "4     @Pontifex @LaityFamilyLife Bongbong Marcos,Sar...  Negative  Hate\n",
       "...                                                 ...       ...   ...\n",
       "2395  Absent for today‚Äôs videyow:\\n1. Bongbong Marco...  Negative  Hate\n",
       "2396  @DisguisedPost @_Nathalieperona Mawalang galan...  Negative  Hate\n",
       "2397  Get ready for 'BongBong' Marcos!\\n\\nHa, what a...  Negative  Hate\n",
       "2398  Sabi ng iba bobo daw si Leni. Bobo pa siya sa ...  Negative  Hate\n",
       "2399  If ever (wag naman sana) manalo si bongbong, i...  Negative  Hate\n",
       "\n",
       "[2400 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_negative = groupedby_sentiment.get_group(\"Negative\")\n",
    "data_df_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d472736d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>In front of a huge crowd, Cebu Governor Gwen G...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3601</th>\n",
       "      <td>ANSABE NG 6 MILLION VIEWS SA KATATAPOS LANG NA...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3602</th>\n",
       "      <td>Mga di nagdidiet for Leni Robredo CHAROTTT</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>Madam President ackkkk keleg iz meh\\nPresident...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3604</th>\n",
       "      <td>üëÄ Bongbong yo-yo üáµüá≠ \\n\\n#Marcos üí∏ https://t.co...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>President Leni Robredo supporters üíö‚úÖ‚òòÔ∏èüå≤üå¥ü•ëüåøüìöü•¶ü•íüçè...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>gonna start muting vp leni pics for now, my dr...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>Sa Gobyernong Tapat, Angat Buhay Lahat! Ang Pr...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>Ang presidente... Leni Robredo\\nBise President...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>@KorekKaJohn parang bagay sayo yung suot ni Ma...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text Sentiment     label\n",
       "3600  In front of a huge crowd, Cebu Governor Gwen G...   Neutral  Non-hate\n",
       "3601  ANSABE NG 6 MILLION VIEWS SA KATATAPOS LANG NA...   Neutral  Non-hate\n",
       "3602         Mga di nagdidiet for Leni Robredo CHAROTTT   Neutral  Non-hate\n",
       "3603  Madam President ackkkk keleg iz meh\\nPresident...   Neutral  Non-hate\n",
       "3604  üëÄ Bongbong yo-yo üáµüá≠ \\n\\n#Marcos üí∏ https://t.co...   Neutral  Non-hate\n",
       "...                                                 ...       ...       ...\n",
       "4795  President Leni Robredo supporters üíö‚úÖ‚òòÔ∏èüå≤üå¥ü•ëüåøüìöü•¶ü•íüçè...   Neutral  Non-hate\n",
       "4796  gonna start muting vp leni pics for now, my dr...   Neutral  Non-hate\n",
       "4797  Sa Gobyernong Tapat, Angat Buhay Lahat! Ang Pr...   Neutral  Non-hate\n",
       "4798  Ang presidente... Leni Robredo\\nBise President...   Neutral  Non-hate\n",
       "4799  @KorekKaJohn parang bagay sayo yung suot ni Ma...   Neutral  Non-hate\n",
       "\n",
       "[1200 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_neutral = groupedby_sentiment.get_group(\"Neutral\")\n",
    "data_df_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9d20c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark Gabriel Ortiz\\AppData\\Local\\Temp\\ipykernel_15300\\2699631638.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_df_nonhate = data_df_positive.append(data_df_neutral)\n",
      "C:\\Users\\Mark Gabriel Ortiz\\AppData\\Local\\Temp\\ipykernel_15300\\2699631638.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_df = data_df_hate.append(data_df_nonhate)\n"
     ]
    }
   ],
   "source": [
    "#binary hate non-hate\n",
    "data_df_hate = data_df_negative.sample(n = 2560, replace=True)\n",
    "\n",
    "data_df_positive = data_df_positive.sample(n = 1280, replace=True)\n",
    "data_df_neutral = data_df_neutral.sample(n = 1280, replace=True)\n",
    "\n",
    "data_df_nonhate = data_df_positive.append(data_df_neutral)\n",
    "\n",
    "data_df = data_df_hate.append(data_df_nonhate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56cefa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.drop(['Sentiment'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f1a120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Kung ako man ang anak ni Loren Legarda, ikahih...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>@frfielpareja Fr. Fiel Pareja, Katoliko po ako...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>We were just talking about your leni robredo a...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Ganyan dapat ang debate, brain challenging. Ka...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>Kawawa talaga mga #Kakampikon Popular Celebrit...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>‚Äúrobredos‚Äù HAHSHSHA SI LENI ROBREDO NA NGA LAN...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>Earlier in the election cycle, it's only Isko ...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>\"Sa Gobyernong Tapat, Angat Buhay Lahat!\"\\n\\nA...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>The way #VoguePhilippines will have President ...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>ANG PRESIDENTE, LENI ROBREDO\\nBISE PRESIDENTE,...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     label\n",
       "464   Kung ako man ang anak ni Loren Legarda, ikahih...      Hate\n",
       "1155  @frfielpareja Fr. Fiel Pareja, Katoliko po ako...      Hate\n",
       "1345  We were just talking about your leni robredo a...      Hate\n",
       "324   Ganyan dapat ang debate, brain challenging. Ka...      Hate\n",
       "2038  Kawawa talaga mga #Kakampikon Popular Celebrit...      Hate\n",
       "...                                                 ...       ...\n",
       "3808  ‚Äúrobredos‚Äù HAHSHSHA SI LENI ROBREDO NA NGA LAN...  Non-hate\n",
       "4475  Earlier in the election cycle, it's only Isko ...  Non-hate\n",
       "3861  \"Sa Gobyernong Tapat, Angat Buhay Lahat!\"\\n\\nA...  Non-hate\n",
       "3985  The way #VoguePhilippines will have President ...  Non-hate\n",
       "3814  ANG PRESIDENTE, LENI ROBREDO\\nBISE PRESIDENTE,...  Non-hate\n",
       "\n",
       "[5120 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_df.to_csv('dataset.csv', index=False)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "803cceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f10c2e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>464</td>\n",
       "      <td>Kung ako man ang anak ni Loren Legarda, ikahih...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1155</td>\n",
       "      <td>@frfielpareja Fr. Fiel Pareja, Katoliko po ako...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1345</td>\n",
       "      <td>We were just talking about your leni robredo a...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324</td>\n",
       "      <td>Ganyan dapat ang debate, brain challenging. Ka...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2038</td>\n",
       "      <td>Kawawa talaga mga #Kakampikon Popular Celebrit...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>3808</td>\n",
       "      <td>‚Äúrobredos‚Äù HAHSHSHA SI LENI ROBREDO NA NGA LAN...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>4475</td>\n",
       "      <td>Earlier in the election cycle, it's only Isko ...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>3861</td>\n",
       "      <td>\"Sa Gobyernong Tapat, Angat Buhay Lahat!\"\\n\\nA...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>3985</td>\n",
       "      <td>The way #VoguePhilippines will have President ...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>3814</td>\n",
       "      <td>ANG PRESIDENTE, LENI ROBREDO\\nBISE PRESIDENTE,...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text     label\n",
       "0       464  Kung ako man ang anak ni Loren Legarda, ikahih...      Hate\n",
       "1      1155  @frfielpareja Fr. Fiel Pareja, Katoliko po ako...      Hate\n",
       "2      1345  We were just talking about your leni robredo a...      Hate\n",
       "3       324  Ganyan dapat ang debate, brain challenging. Ka...      Hate\n",
       "4      2038  Kawawa talaga mga #Kakampikon Popular Celebrit...      Hate\n",
       "...     ...                                                ...       ...\n",
       "5115   3808  ‚Äúrobredos‚Äù HAHSHSHA SI LENI ROBREDO NA NGA LAN...  Non-hate\n",
       "5116   4475  Earlier in the election cycle, it's only Isko ...  Non-hate\n",
       "5117   3861  \"Sa Gobyernong Tapat, Angat Buhay Lahat!\"\\n\\nA...  Non-hate\n",
       "5118   3985  The way #VoguePhilippines will have President ...  Non-hate\n",
       "5119   3814  ANG PRESIDENTE, LENI ROBREDO\\nBISE PRESIDENTE,...  Non-hate\n",
       "\n",
       "[5120 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c63582fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = \"dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b8afaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = tokens[:tokenizer.model_max_length - 2]  # Account for [CLS] and [SEP] tokens\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    return indexed_tokens\n",
    "\n",
    "filipino_stopwords = set(\n",
    "    \"\"\"\n",
    "akin\n",
    "aking\n",
    "ako\n",
    "alin\n",
    "am\n",
    "amin\n",
    "aming\n",
    "ang\n",
    "ano\n",
    "anumang\n",
    "apat\n",
    "at\n",
    "atin\n",
    "ating\n",
    "ay\n",
    "bababa\n",
    "bago\n",
    "bakit\n",
    "bawat\n",
    "bilang\n",
    "dahil\n",
    "dalawa\n",
    "dapat\n",
    "din\n",
    "dito\n",
    "doon\n",
    "gagawin\n",
    "gayunman\n",
    "ginagawa\n",
    "ginawa\n",
    "ginawang\n",
    "gumawa\n",
    "gusto\n",
    "habang\n",
    "hanggang\n",
    "hindi\n",
    "huwag\n",
    "iba\n",
    "ibaba\n",
    "ibabaw\n",
    "ibig\n",
    "ikaw\n",
    "ilagay\n",
    "ilalim\n",
    "ilan\n",
    "inyong\n",
    "isa\n",
    "isang\n",
    "itaas\n",
    "ito\n",
    "iyo\n",
    "iyon\n",
    "iyong\n",
    "ka\n",
    "kahit\n",
    "kailangan\n",
    "kailanman\n",
    "kami\n",
    "kanila\n",
    "kanilang\n",
    "kanino\n",
    "kanya\n",
    "kanyang\n",
    "kapag\n",
    "kapwa\n",
    "karamihan\n",
    "katiyakan\n",
    "katulad\n",
    "kaya\n",
    "kaysa\n",
    "ko\n",
    "kong\n",
    "kulang\n",
    "kumuha\n",
    "kung\n",
    "laban\n",
    "lahat\n",
    "lamang\n",
    "likod\n",
    "lima\n",
    "maaari\n",
    "maaaring\n",
    "maging\n",
    "mahusay\n",
    "makita\n",
    "marami\n",
    "marapat\n",
    "masyado\n",
    "may\n",
    "mayroon\n",
    "mga\n",
    "minsan\n",
    "mismo\n",
    "mula\n",
    "muli\n",
    "na\n",
    "nabanggit\n",
    "naging\n",
    "nagkaroon\n",
    "nais\n",
    "nakita\n",
    "namin\n",
    "napaka\n",
    "narito\n",
    "nasaan\n",
    "ng\n",
    "ngayon\n",
    "ni\n",
    "nila\n",
    "nilang\n",
    "nito\n",
    "niya\n",
    "niyang\n",
    "noon\n",
    "o\n",
    "pa\n",
    "paano\n",
    "pababa\n",
    "paggawa\n",
    "pagitan\n",
    "pagkakaroon\n",
    "pagkatapos\n",
    "palabas\n",
    "pamamagitan\n",
    "panahon\n",
    "pangalawa\n",
    "para\n",
    "paraan\n",
    "pareho\n",
    "pataas\n",
    "pero\n",
    "pumunta\n",
    "pumupunta\n",
    "sa\n",
    "saan\n",
    "sabi\n",
    "sabihin\n",
    "sarili\n",
    "sila\n",
    "sino\n",
    "siya\n",
    "tatlo\n",
    "tayo\n",
    "tulad\n",
    "tungkol\n",
    "una\n",
    "walang\n",
    "\"\"\".split()\n",
    ")\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "# english_stopwords = stopwords.words('english')\n",
    "\n",
    "# search = \"leni robredo bongbong marcos isko moreno domagoso manny pacman pacquiao ping lacson ernie abella leody de guzman norberto gonzales jose montemayor jr faisal mangondato\"\n",
    "# candidatelist = search.split(\" \")\n",
    "\n",
    "# URL Removal\n",
    "def remove_url (text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    \n",
    "    # Use re.sub to replace URLs with an empty string\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "# Emoji Removal\n",
    "def replace_emojis(text):\n",
    "    return emoji.replace_emoji(text, \"\")\n",
    "\n",
    "# Remove Diacritics\n",
    "def remove_diacritics(text):\n",
    "    return unidecode.unidecode(text)\n",
    "\n",
    "# Remove English Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "def remove_english_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Remove Filipino Stop Words\n",
    "def remove_filipino_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in filipino_stopwords]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b3226a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PreProcessing\n",
    "\n",
    "# URL Removal\n",
    "data_df['text'] = data_df['text'].apply(remove_url)\n",
    "\n",
    "# Emoji Removal\n",
    "data_df['text'] = data_df['text'].apply(replace_emojis)\n",
    "\n",
    " # Lowercase\n",
    "# data_df['text'] = data_df['text'].str.lower()\n",
    "\n",
    "# Remove Diacritics\n",
    "data_df['text'] = data_df['text'].apply(remove_diacritics)\n",
    "\n",
    "# Remove symbols and numerics using regex\n",
    "#data_df['text'] = data_df['text'].str.replace(r'[^A-Za-z\\s#]', '', regex=True)\n",
    "data_df['text'] = data_df['text'].str.replace(r'[^a-zA-Z0-9\\s#!?]', '', regex=True)\n",
    "\n",
    "# Remove English Stop Words\n",
    "#data_df['text'] = data_df['text'].apply(remove_english_stopwords)\n",
    "\n",
    "# Remove Filipino Stop Words\n",
    "#data_df['text'] = data_df['text'].apply(remove_filipino_stopwords)\n",
    "\n",
    "data_df.to_csv('sample1.csv', index=False)\n",
    "\n",
    "\n",
    "data_df['text'] = data_df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f32559d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>464</td>\n",
       "      <td>[180, 4380, 170, 2718, 1299, 1126, 1403, 1126,...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1155</td>\n",
       "      <td>[175, 11931, 10387, 17482, 21024, 1161, 175, 1...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1345</td>\n",
       "      <td>[1195, 1127, 1198, 2520, 1164, 1240, 5837, 260...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324</td>\n",
       "      <td>[176, 18266, 1389, 5358, 4163, 1204, 1126, 140...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2038</td>\n",
       "      <td>[24181, 3624, 3624, 27629, 18974, 1161, 17713,...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>3808</td>\n",
       "      <td>[187, 12809, 20792, 1116, 5871, 9524, 9524, 23...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>4475</td>\n",
       "      <td>[2206, 1107, 1103, 1728, 5120, 1157, 1178, 111...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>3861</td>\n",
       "      <td>[21718, 1301, 2665, 10449, 4553, 12999, 2980, ...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>3985</td>\n",
       "      <td>[1103, 1236, 108, 191, 18597, 27008, 10913, 18...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>3814</td>\n",
       "      <td>[1126, 1403, 2084, 1162, 5837, 2605, 187, 1280...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text     label\n",
       "0       464  [180, 4380, 170, 2718, 1299, 1126, 1403, 1126,...      Hate\n",
       "1      1155  [175, 11931, 10387, 17482, 21024, 1161, 175, 1...      Hate\n",
       "2      1345  [1195, 1127, 1198, 2520, 1164, 1240, 5837, 260...      Hate\n",
       "3       324  [176, 18266, 1389, 5358, 4163, 1204, 1126, 140...      Hate\n",
       "4      2038  [24181, 3624, 3624, 27629, 18974, 1161, 17713,...      Hate\n",
       "...     ...                                                ...       ...\n",
       "5115   3808  [187, 12809, 20792, 1116, 5871, 9524, 9524, 23...  Non-hate\n",
       "5116   4475  [2206, 1107, 1103, 1728, 5120, 1157, 1178, 111...  Non-hate\n",
       "5117   3861  [21718, 1301, 2665, 10449, 4553, 12999, 2980, ...  Non-hate\n",
       "5118   3985  [1103, 1236, 108, 191, 18597, 27008, 10913, 18...  Non-hate\n",
       "5119   3814  [1126, 1403, 2084, 1162, 5837, 2605, 187, 1280...  Non-hate\n",
       "\n",
       "[5120 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "274bc204",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3706e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Reduce the number of filters in convolutional layers for example\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=128, kernel_size=2, padding='same')\n",
    "        self.bn1 = nn.BatchNorm1d(128)  # Add Batch Normalization\n",
    "        self.pool1 = nn.MaxPool1d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=32, kernel_size=4, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(32)  # Add Batch Normalization\n",
    "        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.6)  # Increase dropout rate slightly\n",
    "        self.fc = nn.Linear(32, output_dim)  # Change the number of input features to match changes in conv layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        x = embedded.permute(0, 2, 1)\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.bn1(x)  # Add Batch Normalization after activation\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bn2(x)  # Add Batch Normalization after activation\n",
    "        x = self.global_pooling(x).squeeze(2)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9d73f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up iterators\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a9a6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, max_seq_length):\n",
    "        self.data = dataframe\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['text']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "\n",
    "        # Padding and conversion to tensor\n",
    "        padded_text = torch.tensor(text[:self.max_seq_length] + [0] * (self.max_seq_length - len(text)))\n",
    "        return padded_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2db27b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_df, 1000)\n",
    "test_dataset = TextDataset(test_df, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "782d32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_iterator = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce1934a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model hyperparameters\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "EMBEDDING_DIM = 768\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3, 4, 5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# CNN Hyperparameters\n",
    "hidden_dim = 100\n",
    "n_conv_layers = 1\n",
    "kernel_sizes = [2, 3, 4]\n",
    "activation = nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "657020f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CNN model\n",
    "model = CNN(VOCAB_SIZE, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
    "#Initialize CNN model\n",
    "# model = CNN(VOCAB_SIZE, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, hidden_dim, n_conv_layers, kernel_sizes, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6896c237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.9, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-15): 16 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize BERT model (for embedding extraction)\n",
    "bert_model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d06a906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, token in enumerate(tokenizer.get_vocab()):\n",
    "        token_id = tokenizer.convert_tokens_to_ids(token)\n",
    "        token_embedding = bert_model.embeddings.word_embeddings.weight[token_id]\n",
    "        model.embedding.weight[i].data.copy_(token_embedding)\n",
    "\n",
    "bert_parameters = []\n",
    "for layer in bert_model.encoder.layer:\n",
    "    bert_parameters.extend(layer.parameters())\n",
    "\n",
    "# Create AdamW optimizer with custom hyperparameters for BERT embeddings\n",
    "bert_learning_rate = 2e-5  # Adjust as needed\n",
    "bert_optimizer = optim.AdamW(bert_parameters, lr=bert_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc3596cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>464</td>\n",
       "      <td>[180, 4380, 170, 2718, 1299, 1126, 1403, 1126,...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1155</td>\n",
       "      <td>[175, 11931, 10387, 17482, 21024, 1161, 175, 1...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1345</td>\n",
       "      <td>[1195, 1127, 1198, 2520, 1164, 1240, 5837, 260...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324</td>\n",
       "      <td>[176, 18266, 1389, 5358, 4163, 1204, 1126, 140...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2038</td>\n",
       "      <td>[24181, 3624, 3624, 27629, 18974, 1161, 17713,...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>3808</td>\n",
       "      <td>[187, 12809, 20792, 1116, 5871, 9524, 9524, 23...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>4475</td>\n",
       "      <td>[2206, 1107, 1103, 1728, 5120, 1157, 1178, 111...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>3861</td>\n",
       "      <td>[21718, 1301, 2665, 10449, 4553, 12999, 2980, ...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>3985</td>\n",
       "      <td>[1103, 1236, 108, 191, 18597, 27008, 10913, 18...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>3814</td>\n",
       "      <td>[1126, 1403, 2084, 1162, 5837, 2605, 187, 1280...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text     label\n",
       "0       464  [180, 4380, 170, 2718, 1299, 1126, 1403, 1126,...      Hate\n",
       "1      1155  [175, 11931, 10387, 17482, 21024, 1161, 175, 1...      Hate\n",
       "2      1345  [1195, 1127, 1198, 2520, 1164, 1240, 5837, 260...      Hate\n",
       "3       324  [176, 18266, 1389, 5358, 4163, 1204, 1126, 140...      Hate\n",
       "4      2038  [24181, 3624, 3624, 27629, 18974, 1161, 17713,...      Hate\n",
       "...     ...                                                ...       ...\n",
       "5115   3808  [187, 12809, 20792, 1116, 5871, 9524, 9524, 23...  Non-hate\n",
       "5116   4475  [2206, 1107, 1103, 1728, 5120, 1157, 1178, 111...  Non-hate\n",
       "5117   3861  [21718, 1301, 2665, 10449, 4553, 12999, 2980, ...  Non-hate\n",
       "5118   3985  [1103, 1236, 108, 191, 18597, 27008, 10913, 18...  Non-hate\n",
       "5119   3814  [1126, 1403, 2084, 1162, 5837, 2605, 187, 1280...  Non-hate\n",
       "\n",
       "[5120 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02c4f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(model.parameters())\n",
    "# Your custom hyperparameters\n",
    "learning_rate = 0.001\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "epsilon = 1e-08\n",
    "weight_decay = 0.0\n",
    "\n",
    "# Create Adam optimizer with custom hyperparameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta_1, beta_2), eps=epsilon, weight_decay=weight_decay)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e33b7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train(model, iterator):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for text_batch, label_batch in iterator:\n",
    "        # Extract text sequences from the text_batch tensor\n",
    "        texts = text_batch\n",
    "        \n",
    "        # Extract and process labels\n",
    "        labels = [1 if label == 'Hate' else 0 for label in label_batch]  # Example conversion\n",
    "        \n",
    "        texts = texts.to(device)  # Move to device if needed\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).to(device)  # Convert to tensor\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(texts).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "# Evaluate function\n",
    "def evaluate(model, iterator):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []  # Declare the true_labels list\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch in iterator:\n",
    "            texts = text_batch  # Extract text sequences\n",
    "            labels = [1 if label == 'Hate' else 0 for label in label_batch]  # Example conversion\n",
    "            \n",
    "            texts = texts.to(device)  # Move to device\n",
    "            labels = torch.tensor(labels, dtype=torch.float32).to(device)  # Convert to tensor\n",
    "            \n",
    "            predictions = model(texts).squeeze(1)\n",
    "            loss = criterion(predictions, labels)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            predicted_labels.extend(torch.round(torch.sigmoid(predictions)).cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy, f1, precision, recall\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    \n",
    "    return epoch_loss / len(iterator), accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3ec217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark Gabriel Ortiz\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\Convolution.cpp:1004.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 1.568\n",
      "\tTest Loss: 0.581\n",
      "\tAccuracy: 0.6846 | F1-Score: 0.7498\n",
      "\tPrecision: 0.6181 | Recall: 0.9528\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.793\n",
      "\tTest Loss: 0.381\n",
      "\tAccuracy: 0.8428 | F1-Score: 0.8511\n",
      "\tPrecision: 0.8028 | Recall: 0.9055\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.518\n",
      "\tTest Loss: 0.312\n",
      "\tAccuracy: 0.8818 | F1-Score: 0.8874\n",
      "\tPrecision: 0.8413 | Recall: 0.9390\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.322\n",
      "\tTest Loss: 0.283\n",
      "\tAccuracy: 0.9033 | F1-Score: 0.9049\n",
      "\tPrecision: 0.8837 | Recall: 0.9272\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.201\n",
      "\tTest Loss: 0.288\n",
      "\tAccuracy: 0.9043 | F1-Score: 0.9061\n",
      "\tPrecision: 0.8825 | Recall: 0.9311\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m N_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EPOCHS):\n\u001b[1;32m----> 3\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     test_loss, accuracy, f1, precision, recall \u001b[38;5;241m=\u001b[39m evaluate(model, test_iterator)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m     15\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Convert to tensor\u001b[39;00m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 18\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(predictions, labels)\n\u001b[0;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     22\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m---> 23\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_dropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     x \u001b[38;5;241m=\u001b[39m embedded\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[1;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_iterator)\n",
    "    test_loss, accuracy, f1, precision, recall = evaluate(model, test_iterator)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\tTest Loss: {test_loss:.3f}')\n",
    "    print(f'\\tAccuracy: {accuracy:.4f} | F1-Score: {f1:.4f}')\n",
    "    print(f'\\tPrecision: {precision:.4f} | Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee1e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dece720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da131100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
