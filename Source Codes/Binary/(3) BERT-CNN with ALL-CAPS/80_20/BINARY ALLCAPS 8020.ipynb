{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5486b8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from transformers import AdamW\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import csv\n",
    "import re\n",
    "import validators\n",
    "import emoji\n",
    "import unidecode\n",
    "import nltk\n",
    "import pickle\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6954a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "SEED = 1235\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# BERT Hyperparameters (ADDITION)\n",
    "n_bert_layers = 16  # Assuming the base model has 12 layers\n",
    "bert_lr = 0.001\n",
    "pooling_strategy = 'cls'  # Options: 'cls', 'mean', 'max'\n",
    "bert_hidden_size = 768  # Adjust based on your BERT model\n",
    "max_seq_length = 128\n",
    "fine_tune_strategy = 'full'  # Options: 'full', 'last_layer'\n",
    "bert_dropout = 0.9  # Adjust based on BERT model specifications\n",
    "\n",
    "max_seq_length = 128  # This should match the max_seq_length used in BERT model\n",
    "padding_strategy = 'max_length'  # Options: 'max_length', 'do_not_pad', 'longest'\n",
    "truncation_strategy = 'longest_first'  # Options: 'longest_first', 'only_first', 'only_second'\n",
    "do_lower_case = True  # Set to False if using a cased model\n",
    "\n",
    "config = BertConfig(\n",
    "    num_hidden_layers=n_bert_layers,\n",
    "    hidden_size=bert_hidden_size,\n",
    "    num_attention_heads=24,  # Assuming 12 attention heads\n",
    "    intermediate_size=4 * bert_hidden_size,  # Default value in BERT\n",
    "    hidden_dropout_prob=bert_dropout,\n",
    "    attention_probs_dropout_prob=bert_dropout,\n",
    ")\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          max_length=max_seq_length,\n",
    "                                          padding=padding_strategy,\n",
    "                                          truncation=truncation_strategy,\n",
    "                                          do_lower_case=do_lower_case)\n",
    "# Load the BERT model with the custom configuration\n",
    "bert_model = BertModel(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0815b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/admin/Downloads/Binary_dataset.csv\"\n",
    "data_df = pd.read_csv(data_path)\n",
    "data_df = data_df.rename(columns={'Tweet Content': 'text', 'Label': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fd15764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Worst Bong ever. https://t.co/QA7R8VYppC</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what i dont like about leni robredo's platform...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ito ang tunay na survey ni VP Leni Robredo #1 ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3) BBM sued for Pork Barrel Scam\\n\\nhttps://t...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sabog din sumagot tong si Norberto Gonzales no...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text Sentiment label\n",
       "0           Worst Bong ever. https://t.co/QA7R8VYppC  Negative  Hate\n",
       "1  what i dont like about leni robredo's platform...  Negative  Hate\n",
       "2  Ito ang tunay na survey ni VP Leni Robredo #1 ...  Negative  Hate\n",
       "3  (3) BBM sued for Pork Barrel Scam\\n\\nhttps://t...  Negative  Hate\n",
       "4  Sabog din sumagot tong si Norberto Gonzales no...  Negative  Hate"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d3add86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>I took The Blind Test and my top candidates ar...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>\"True leader show up and man up.\" - VP Leni Ro...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>Leni Robredo for president cutie ðŸ¤žðŸŒ¸</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>Ako si Christian Tan, kabataan at kaisa ni Bon...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>Ate @xlykable Letâ€™s support VP Leni and Sen. K...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>Just because Aiai did not supported Leni Robre...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>â€œMga kababayan, summon the warrior in you and ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>@thekiarasworld Now I know that not all of the...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3838</th>\n",
       "      <td>Ping Lacson Ang may Plano sa bansa\\n\\n#KayPing...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3839</th>\n",
       "      <td>@dfenderwoborder Pls watch &amp;amp; share.  Ang g...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text Sentiment     label\n",
       "2560  I took The Blind Test and my top candidates ar...  Positive  Non-hate\n",
       "2561  \"True leader show up and man up.\" - VP Leni Ro...  Positive  Non-hate\n",
       "2562                Leni Robredo for president cutie ðŸ¤žðŸŒ¸  Positive  Non-hate\n",
       "2563  Ako si Christian Tan, kabataan at kaisa ni Bon...  Positive  Non-hate\n",
       "2564  Ate @xlykable Letâ€™s support VP Leni and Sen. K...  Positive  Non-hate\n",
       "...                                                 ...       ...       ...\n",
       "3835  Just because Aiai did not supported Leni Robre...  Positive  Non-hate\n",
       "3836  â€œMga kababayan, summon the warrior in you and ...  Positive  Non-hate\n",
       "3837  @thekiarasworld Now I know that not all of the...  Positive  Non-hate\n",
       "3838  Ping Lacson Ang may Plano sa bansa\\n\\n#KayPing...  Positive  Non-hate\n",
       "3839  @dfenderwoborder Pls watch &amp; share.  Ang g...  Positive  Non-hate\n",
       "\n",
       "[1280 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupedby_sentiment = data_df.groupby(data_df.Sentiment)\n",
    "data_df_positive = groupedby_sentiment.get_group(\"Positive\")\n",
    "data_df_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eaa751cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Worst Bong ever. https://t.co/QA7R8VYppC</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what i dont like about leni robredo's platform...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ito ang tunay na survey ni VP Leni Robredo #1 ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3) BBM sued for Pork Barrel Scam\\n\\nhttps://t...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sabog din sumagot tong si Norberto Gonzales no...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>Headline: The ambitious presidential candidate...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>Norberto Gonzales is right, its a missed oppor...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>The audacity to call Leni Robredo \"bobo\", \" ta...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>Bongbong Marcos is a Nazi. https://t.co/gY3xHb...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>Ang humihingi ng Respeto dapat marunong din Ru...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text Sentiment label\n",
       "0              Worst Bong ever. https://t.co/QA7R8VYppC  Negative  Hate\n",
       "1     what i dont like about leni robredo's platform...  Negative  Hate\n",
       "2     Ito ang tunay na survey ni VP Leni Robredo #1 ...  Negative  Hate\n",
       "3     (3) BBM sued for Pork Barrel Scam\\n\\nhttps://t...  Negative  Hate\n",
       "4     Sabog din sumagot tong si Norberto Gonzales no...  Negative  Hate\n",
       "...                                                 ...       ...   ...\n",
       "2555  Headline: The ambitious presidential candidate...  Negative  Hate\n",
       "2556  Norberto Gonzales is right, its a missed oppor...  Negative  Hate\n",
       "2557  The audacity to call Leni Robredo \"bobo\", \" ta...  Negative  Hate\n",
       "2558  Bongbong Marcos is a Nazi. https://t.co/gY3xHb...  Negative  Hate\n",
       "2559  Ang humihingi ng Respeto dapat marunong din Ru...  Negative  Hate\n",
       "\n",
       "[2560 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_negative = groupedby_sentiment.get_group(\"Negative\")\n",
    "data_df_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d472736d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>bongbong marcos dot com</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>Grabe pala talaga yung actions ni Leni Robredo...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3842</th>\n",
       "      <td>â€œNgayong darating na halalan, ang tatanglaw sa...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>For this COMELEC debate:\\n\\nValedictorian: Len...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>Focus on the ball kakampinks\\n\\nPresident Leni...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>President Leni Robredo and Vice President Kiko...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>@jillrobredo ðŸŒºðŸŒºðŸŒº\\nthank you din kay @maraceped...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>LOOK: Presidential candidate Bongbong Marcos m...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>@itsmaxandcheese Leni Robredo for President 2022</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>LENI ROBREDO FOR PRESIDENT. https://t.co/b14K2...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text Sentiment     label\n",
       "3840                            bongbong marcos dot com   Neutral  Non-hate\n",
       "3841  Grabe pala talaga yung actions ni Leni Robredo...   Neutral  Non-hate\n",
       "3842  â€œNgayong darating na halalan, ang tatanglaw sa...   Neutral  Non-hate\n",
       "3843  For this COMELEC debate:\\n\\nValedictorian: Len...   Neutral  Non-hate\n",
       "3844  Focus on the ball kakampinks\\n\\nPresident Leni...   Neutral  Non-hate\n",
       "...                                                 ...       ...       ...\n",
       "5115  President Leni Robredo and Vice President Kiko...   Neutral  Non-hate\n",
       "5116  @jillrobredo ðŸŒºðŸŒºðŸŒº\\nthank you din kay @maraceped...   Neutral  Non-hate\n",
       "5117  LOOK: Presidential candidate Bongbong Marcos m...   Neutral  Non-hate\n",
       "5118   @itsmaxandcheese Leni Robredo for President 2022   Neutral  Non-hate\n",
       "5119  LENI ROBREDO FOR PRESIDENT. https://t.co/b14K2...   Neutral  Non-hate\n",
       "\n",
       "[1280 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_neutral = groupedby_sentiment.get_group(\"Neutral\")\n",
    "data_df_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9d20c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4884\\2699631638.py:7: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_df_nonhate = data_df_positive.append(data_df_neutral)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4884\\2699631638.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_df = data_df_hate.append(data_df_nonhate)\n"
     ]
    }
   ],
   "source": [
    "#binary hate non-hate\n",
    "data_df_hate = data_df_negative.sample(n = 2560, replace=True)\n",
    "\n",
    "data_df_positive = data_df_positive.sample(n = 1280, replace=True)\n",
    "data_df_neutral = data_df_neutral.sample(n = 1280, replace=True)\n",
    "\n",
    "data_df_nonhate = data_df_positive.append(data_df_neutral)\n",
    "\n",
    "data_df = data_df_hate.append(data_df_nonhate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56cefa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.drop(['Sentiment'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6f1a120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>@jacky_ledesma @LeonardoTalle12 @1stylemomsi N...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>#FrontlineTonight | Matapos tawaging spoiled c...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>Kaya di nag attend sa debate sponsored by SMNI...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>@charlangqtt pangbatikos nila sa BBM, initiall...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>@jhessaunknown @yyangjw00 anyone could fit the...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4766</th>\n",
       "      <td>Sa Gobyernong Tapat, Angat Buhay Lahat! \\n\\nAk...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>the 17th president of the Republic of the Phil...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>Letâ€™s pray.  Leni Robredo &amp;amp; Kiko Pangilina...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>Titindig. Lalaban. Mananalo.\\n\\nIsang malaking...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017</th>\n",
       "      <td>Aerial shot ng isinagawang miting de avance pa...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     label\n",
       "2536  @jacky_ledesma @LeonardoTalle12 @1stylemomsi N...      Hate\n",
       "1624  #FrontlineTonight | Matapos tawaging spoiled c...      Hate\n",
       "1008  Kaya di nag attend sa debate sponsored by SMNI...      Hate\n",
       "1637  @charlangqtt pangbatikos nila sa BBM, initiall...      Hate\n",
       "2264  @jhessaunknown @yyangjw00 anyone could fit the...      Hate\n",
       "...                                                 ...       ...\n",
       "4766  Sa Gobyernong Tapat, Angat Buhay Lahat! \\n\\nAk...  Non-hate\n",
       "3929  the 17th president of the Republic of the Phil...  Non-hate\n",
       "4365  Letâ€™s pray.  Leni Robredo &amp; Kiko Pangilina...  Non-hate\n",
       "3896  Titindig. Lalaban. Mananalo.\\n\\nIsang malaking...  Non-hate\n",
       "5017  Aerial shot ng isinagawang miting de avance pa...  Non-hate\n",
       "\n",
       "[5120 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_df.to_csv('dataset.csv', index=False)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "803cceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f10c2e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2536</td>\n",
       "      <td>@jacky_ledesma @LeonardoTalle12 @1stylemomsi N...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1624</td>\n",
       "      <td>#FrontlineTonight | Matapos tawaging spoiled c...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1008</td>\n",
       "      <td>Kaya di nag attend sa debate sponsored by SMNI...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1637</td>\n",
       "      <td>@charlangqtt pangbatikos nila sa BBM, initiall...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2264</td>\n",
       "      <td>@jhessaunknown @yyangjw00 anyone could fit the...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>4766</td>\n",
       "      <td>Sa Gobyernong Tapat, Angat Buhay Lahat! \\n\\nAk...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>3929</td>\n",
       "      <td>the 17th president of the Republic of the Phil...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>4365</td>\n",
       "      <td>Letâ€™s pray.  Leni Robredo &amp;amp; Kiko Pangilina...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>3896</td>\n",
       "      <td>Titindig. Lalaban. Mananalo.\\n\\nIsang malaking...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>5017</td>\n",
       "      <td>Aerial shot ng isinagawang miting de avance pa...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text     label\n",
       "0      2536  @jacky_ledesma @LeonardoTalle12 @1stylemomsi N...      Hate\n",
       "1      1624  #FrontlineTonight | Matapos tawaging spoiled c...      Hate\n",
       "2      1008  Kaya di nag attend sa debate sponsored by SMNI...      Hate\n",
       "3      1637  @charlangqtt pangbatikos nila sa BBM, initiall...      Hate\n",
       "4      2264  @jhessaunknown @yyangjw00 anyone could fit the...      Hate\n",
       "...     ...                                                ...       ...\n",
       "5115   4766  Sa Gobyernong Tapat, Angat Buhay Lahat! \\n\\nAk...  Non-hate\n",
       "5116   3929  the 17th president of the Republic of the Phil...  Non-hate\n",
       "5117   4365  Letâ€™s pray.  Leni Robredo &amp; Kiko Pangilina...  Non-hate\n",
       "5118   3896  Titindig. Lalaban. Mananalo.\\n\\nIsang malaking...  Non-hate\n",
       "5119   5017  Aerial shot ng isinagawang miting de avance pa...  Non-hate\n",
       "\n",
       "[5120 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c63582fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = \"dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b8afaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = tokens[:tokenizer.model_max_length - 2]  # Account for [CLS] and [SEP] tokens\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    return indexed_tokens\n",
    "\n",
    "filipino_stopwords = set(\n",
    "    \"\"\"\n",
    "akin\n",
    "aking\n",
    "ako\n",
    "alin\n",
    "am\n",
    "amin\n",
    "aming\n",
    "ang\n",
    "ano\n",
    "anumang\n",
    "apat\n",
    "at\n",
    "atin\n",
    "ating\n",
    "ay\n",
    "bababa\n",
    "bago\n",
    "bakit\n",
    "bawat\n",
    "bilang\n",
    "dahil\n",
    "dalawa\n",
    "dapat\n",
    "din\n",
    "dito\n",
    "doon\n",
    "gagawin\n",
    "gayunman\n",
    "ginagawa\n",
    "ginawa\n",
    "ginawang\n",
    "gumawa\n",
    "gusto\n",
    "habang\n",
    "hanggang\n",
    "hindi\n",
    "huwag\n",
    "iba\n",
    "ibaba\n",
    "ibabaw\n",
    "ibig\n",
    "ikaw\n",
    "ilagay\n",
    "ilalim\n",
    "ilan\n",
    "inyong\n",
    "isa\n",
    "isang\n",
    "itaas\n",
    "ito\n",
    "iyo\n",
    "iyon\n",
    "iyong\n",
    "ka\n",
    "kahit\n",
    "kailangan\n",
    "kailanman\n",
    "kami\n",
    "kanila\n",
    "kanilang\n",
    "kanino\n",
    "kanya\n",
    "kanyang\n",
    "kapag\n",
    "kapwa\n",
    "karamihan\n",
    "katiyakan\n",
    "katulad\n",
    "kaya\n",
    "kaysa\n",
    "ko\n",
    "kong\n",
    "kulang\n",
    "kumuha\n",
    "kung\n",
    "laban\n",
    "lahat\n",
    "lamang\n",
    "likod\n",
    "lima\n",
    "maaari\n",
    "maaaring\n",
    "maging\n",
    "mahusay\n",
    "makita\n",
    "marami\n",
    "marapat\n",
    "masyado\n",
    "may\n",
    "mayroon\n",
    "mga\n",
    "minsan\n",
    "mismo\n",
    "mula\n",
    "muli\n",
    "na\n",
    "nabanggit\n",
    "naging\n",
    "nagkaroon\n",
    "nais\n",
    "nakita\n",
    "namin\n",
    "napaka\n",
    "narito\n",
    "nasaan\n",
    "ng\n",
    "ngayon\n",
    "ni\n",
    "nila\n",
    "nilang\n",
    "nito\n",
    "niya\n",
    "niyang\n",
    "noon\n",
    "o\n",
    "pa\n",
    "paano\n",
    "pababa\n",
    "paggawa\n",
    "pagitan\n",
    "pagkakaroon\n",
    "pagkatapos\n",
    "palabas\n",
    "pamamagitan\n",
    "panahon\n",
    "pangalawa\n",
    "para\n",
    "paraan\n",
    "pareho\n",
    "pataas\n",
    "pero\n",
    "pumunta\n",
    "pumupunta\n",
    "sa\n",
    "saan\n",
    "sabi\n",
    "sabihin\n",
    "sarili\n",
    "sila\n",
    "sino\n",
    "siya\n",
    "tatlo\n",
    "tayo\n",
    "tulad\n",
    "tungkol\n",
    "una\n",
    "walang\n",
    "\"\"\".split()\n",
    ")\n",
    "\n",
    "# Date De-Identification\n",
    "def remove_mentions(text):\n",
    "    mention_pattern = re.compile(r'@\\w+')\n",
    "    \n",
    "    # Use re.sub to remove mentions\n",
    "    cleaned_text = mention_pattern.sub('', text)\n",
    "    \n",
    "    # Remove extra spaces and strip leading/trailing spaces\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# URL Removal\n",
    "def remove_url(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    \n",
    "    # Use re.sub to remove URLs\n",
    "    cleaned_text = url_pattern.sub('', text)\n",
    "    \n",
    "    # Remove extra spaces and strip leading/trailing spaces\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Special Characters Removal\n",
    "def remove_special_characters(text):\n",
    "    text = emoji.replace_emoji(text, replace=\"[emoji]\")\n",
    "    \n",
    "    # Split the text into words\n",
    "    words = text.split(\" \")\n",
    "    \n",
    "    # Initialize an empty string to store the cleaned text\n",
    "    cleaned_text = \"\"\n",
    "    \n",
    "    # Iterate through each word\n",
    "    for word in words:\n",
    "        # Check if the word contains only special characters or \"[emoji]\"\n",
    "        if not (re.match(r\"^[_\\W]+$\", word) or \"[emoji]\" in word):\n",
    "            if len(cleaned_text) == 0:\n",
    "                cleaned_text = f\"{word}\"\n",
    "            else:\n",
    "                cleaned_text = f\"{cleaned_text} {word}\"\n",
    "                \n",
    "    # Remove diacritics\n",
    "    text_no_diacritics = unidecode.unidecode(cleaned_text)\n",
    "\n",
    "    # Split the text into words\n",
    "    sentence = text_no_diacritics.split(\" \")\n",
    "    output = \"\"\n",
    "\n",
    "    # Remove special characters and numerics\n",
    "    for part in sentence:\n",
    "        part = re.sub(\"[^A-Za-z ]+$\", \"\", part)\n",
    "        part = re.sub(\"^[^A-Za-z #]+\", \"\", part)\n",
    "        if not (len(part) <= 1 or re.match(r\"[^a-zA-Z]\", part)):\n",
    "            if len(output) == 0:\n",
    "                output = f\"{part}\"\n",
    "            else:\n",
    "                output = f\"{output} {part}\"\n",
    "\n",
    "    # Remove extra spaces and strip leading/trailing spaces\n",
    "    cleaned_text = ' '.join(output.split())\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Remove English Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "# Remove English Stop Words\n",
    "def remove_english_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Remove extra spaces and strip leading/trailing spaces\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Remove Filipino Stop Words\n",
    "def remove_filipino_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in filipino_stopwords]\n",
    "    \n",
    "    # Remove extra spaces and strip leading/trailing spaces\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "  \n",
    "    return cleaned_text\n",
    "\n",
    "# Candidate Name Removal\n",
    "def remove_candidate_names(text):\n",
    "    candidatelist = \"leni robredo bongbong marcos isko moreno domagoso manny pacman pacquiao ping lacson ernie abella leody de guzman norberto gonzales jose montemayor jr faisal mangondato\"\n",
    "    candidatelist = candidatelist.split()\n",
    "    candidate_pattern = re.compile(r'\\b(?:' + '|'.join(map(re.escape, candidatelist)) + r')\\b', re.IGNORECASE)\n",
    "    \n",
    "    # Use re.sub to remove candidate names\n",
    "    cleaned_text = candidate_pattern.sub('', text)\n",
    "    \n",
    "    # Remove extra spaces and strip leading/trailing spaces\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "        \n",
    "    return cleaned_text\n",
    "\n",
    "# Hashtag Removal\n",
    "def remove_hashtags(text):\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Initialize an empty list to store cleaned words\n",
    "    cleaned_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Check if the word is a hashtag (starts with #)\n",
    "        if not word.startswith('#'):\n",
    "            cleaned_words.append(word)\n",
    "    \n",
    "    # Join the cleaned words into a single string\n",
    "    cleaned_text = ' '.join(cleaned_words)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Hashtag Removal\n",
    "def remove_hashtag_symbols(text):\n",
    "    # Use regular expression to remove \"#\" before words\n",
    "    cleaned_text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    \n",
    "    # Remove extra spaces and strip leading/trailing spaces\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4af5cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_except_all_caps(text):\n",
    "    cleaned_text = remove_hashtag_symbols(text)\n",
    "    \n",
    "    words = cleaned_text.split()\n",
    "    filtered_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word.isupper() and not word.istitle():\n",
    "            filtered_words.append(word)\n",
    "        else:\n",
    "            filtered_words.append(re.sub(r'([A-Z][a-z]+)', lambda x: x.group(1).lower(), word))\n",
    "            \n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b3226a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad02bb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  Napaka nonsense ng tanong sir walang substance. Next time sumagot ka ayun sa kong ano ang nasa isip at puso mo hindi galing sa script na binibigay sayo. I respect your choice pero sana suporthan nyo si leni robredo kahit wala na sya pakinabang sa mga dilawan \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  #FrontlineTonight | Matapos tawaging spoiled child at weak leader, tila nag-iba na ang pagtingin ni Pres. Rodrigo Duterte kay presidential bet Bongbong Marcos Jr. #BilangPilipino2022 | via https://t.co/nsYfN61srv \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Kaya di nag attend sa debate sponsored by SMNI si ma dumb leni robredo, mapapahiya at mabubutata sya ni Prof. Carlos. \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  pangbatikos nila sa BBM, initially BongBong Marcos gaya ng ginawa nila dati sa DDS na Dingdong Dantes Supporters ðŸ¤£ \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  anyone could fit the bill there's jinggoy who's guilty of plunder and jv who has graft charges of course included din si bongbong marcos who's convicted of tax evasion pero hindi lang naman sya ang magnanakaw na tumatakbo ngayon \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  gumaganern, basta umunlad ang pinas? baka basta umunlad buhay ng mga marcos C'MON WE ALL KNOW WHAT BONGBONG AND FAM DID, DON'T LIE TO URSELF HUN https://t.co/Q1WS7t5mG7 \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Ok si Norberto Gonzales at Ernesto Abella, men of wisdom but lacks. BBM has the energy and has true understanding and love for the country. Leody, ok sana kaso baluktot ang pagintindi sa use of force ng gobyerno against sa kanila. \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Disowning love ones, cancelling businesses, bullying someone because they're not supporting Leni and badmouthing against BBM are the results of negative campaigns of Kakampinks and Leni Robredo herself. #EvilLeni #Homewrecker \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Dapat nga mga hipokritong katoliko, mga botante, at mga kabataan, and I mean who votes Leni Robredo and Kiko that promotes hate and toxicity, contrast with the message of Jesus Christ of Love and Unity. Think Again, Hypocrites! https://t.co/mZsEEqfrSZ \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Bongbong Marcos' responses are really bland and abstract. We don't want a President who has no concrete and specific plans for our country. We demand for a President who is driven by experiences, sincere, and free from stains of corruption. Let that sink in. \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data De-Identification\n",
    "data_df['text'] = data_df['text'].apply(remove_mentions)\n",
    "\n",
    "for i in range(10):\n",
    "    text = data_df[\"text\"][i]\n",
    "    label = data_df[\"label\"][i]\n",
    "\n",
    "    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1899b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  Napaka nonsense ng tanong sir walang substance. Next time sumagot ka ayun sa kong ano ang nasa isip at puso mo hindi galing sa script na binibigay sayo. I respect your choice pero sana suporthan nyo si leni robredo kahit wala na sya pakinabang sa mga dilawan \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  #FrontlineTonight | Matapos tawaging spoiled child at weak leader, tila nag-iba na ang pagtingin ni Pres. Rodrigo Duterte kay presidential bet Bongbong Marcos Jr. #BilangPilipino2022 | via \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Kaya di nag attend sa debate sponsored by SMNI si ma dumb leni robredo, mapapahiya at mabubutata sya ni Prof. Carlos. \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  pangbatikos nila sa BBM, initially BongBong Marcos gaya ng ginawa nila dati sa DDS na Dingdong Dantes Supporters ðŸ¤£ \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  anyone could fit the bill there's jinggoy who's guilty of plunder and jv who has graft charges of course included din si bongbong marcos who's convicted of tax evasion pero hindi lang naman sya ang magnanakaw na tumatakbo ngayon \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  gumaganern, basta umunlad ang pinas? baka basta umunlad buhay ng mga marcos C'MON WE ALL KNOW WHAT BONGBONG AND FAM DID, DON'T LIE TO URSELF HUN \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Ok si Norberto Gonzales at Ernesto Abella, men of wisdom but lacks. BBM has the energy and has true understanding and love for the country. Leody, ok sana kaso baluktot ang pagintindi sa use of force ng gobyerno against sa kanila. \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Disowning love ones, cancelling businesses, bullying someone because they're not supporting Leni and badmouthing against BBM are the results of negative campaigns of Kakampinks and Leni Robredo herself. #EvilLeni #Homewrecker \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Dapat nga mga hipokritong katoliko, mga botante, at mga kabataan, and I mean who votes Leni Robredo and Kiko that promotes hate and toxicity, contrast with the message of Jesus Christ of Love and Unity. Think Again, Hypocrites! \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Bongbong Marcos' responses are really bland and abstract. We don't want a President who has no concrete and specific plans for our country. We demand for a President who is driven by experiences, sincere, and free from stains of corruption. Let that sink in. \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# URL Removal\n",
    "data_df['text'] = data_df['text'].apply(remove_url)\n",
    "\n",
    "for i in range(10):\n",
    "    text = data_df[\"text\"][i]\n",
    "    label = data_df[\"label\"][i]\n",
    "\n",
    "    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50e8dc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  Napaka nonsense ng tanong sir walang substance Next time sumagot ka ayun sa kong ano ang nasa isip at puso mo hindi galing sa script na binibigay sayo respect your choice pero sana suporthan nyo si leni robredo kahit wala na sya pakinabang sa mga dilawan \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Matapos tawaging spoiled child at weak leader tila nag-iba na ang pagtingin ni Pres Rodrigo Duterte kay presidential bet Bongbong Marcos Jr via \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Kaya di nag attend sa debate sponsored by SMNI si ma dumb leni robredo mapapahiya at mabubutata sya ni Prof Carlos \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  pangbatikos nila sa BBM initially BongBong Marcos gaya ng ginawa nila dati sa DDS na Dingdong Dantes Supporters \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  anyone could fit the bill there's jinggoy who's guilty of plunder and jv who has graft charges of course included din si bongbong marcos who's convicted of tax evasion pero hindi lang naman sya ang magnanakaw na tumatakbo ngayon \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  gumaganern basta umunlad ang pinas baka basta umunlad buhay ng mga marcos C'MON WE ALL KNOW WHAT BONGBONG AND FAM DID DON'T LIE TO URSELF HUN \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Ok si Norberto Gonzales at Ernesto Abella men of wisdom but lacks BBM has the energy and has true understanding and love for the country Leody ok sana kaso baluktot ang pagintindi sa use of force ng gobyerno against sa kanila \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Disowning love ones cancelling businesses bullying someone because they're not supporting Leni and badmouthing against BBM are the results of negative campaigns of Kakampinks and Leni Robredo herself \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Dapat nga mga hipokritong katoliko mga botante at mga kabataan and mean who votes Leni Robredo and Kiko that promotes hate and toxicity contrast with the message of Jesus Christ of Love and Unity Think Again Hypocrites \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  Bongbong Marcos responses are really bland and abstract We don't want President who has no concrete and specific plans for our country We demand for President who is driven by experiences sincere and free from stains of corruption Let that sink in \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Special Characters Removal\n",
    "data_df['text'] = data_df['text'].apply(remove_special_characters)\n",
    "\n",
    "for i in range(10):\n",
    "    text = data_df[\"text\"][i]\n",
    "    label = data_df[\"label\"][i]\n",
    "\n",
    "    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7b2db5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  napaka nonsense ng tanong sir walang substance next time sumagot ka ayun sa kong ano ang nasa isip at puso mo hindi galing sa script na binibigay sayo respect your choice pero sana suporthan nyo si leni robredo kahit wala na sya pakinabang sa mga dilawan \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  matapos tawaging spoiled child at weak leader tila nag-iba na ang pagtingin ni pres rodrigo duterte kay presidential bet bongbong marcos jr via \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  kaya di nag attend sa debate sponsored by SMNI si ma dumb leni robredo mapapahiya at mabubutata sya ni prof carlos \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  pangbatikos nila sa BBM initially bongbong marcos gaya ng ginawa nila dati sa DDS na dingdong dantes supporters \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  anyone could fit the bill there's jinggoy who's guilty of plunder and jv who has graft charges of course included din si bongbong marcos who's convicted of tax evasion pero hindi lang naman sya ang magnanakaw na tumatakbo ngayon \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  gumaganern basta umunlad ang pinas baka basta umunlad buhay ng mga marcos C'MON WE ALL KNOW WHAT BONGBONG AND FAM DID DON'T LIE TO URSELF HUN \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  ok si norberto gonzales at ernesto abella men of wisdom but lacks BBM has the energy and has true understanding and love for the country leody ok sana kaso baluktot ang pagintindi sa use of force ng gobyerno against sa kanila \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  disowning love ones cancelling businesses bullying someone because they're not supporting leni and badmouthing against BBM are the results of negative campaigns of kakampinks and leni robredo herself \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  dapat nga mga hipokritong katoliko mga botante at mga kabataan and mean who votes leni robredo and kiko that promotes hate and toxicity contrast with the message of jesus christ of love and unity think again hypocrites \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  bongbong marcos responses are really bland and abstract we don't want president who has no concrete and specific plans for our country we demand for president who is driven by experiences sincere and free from stains of corruption let that sink in \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lowercase\n",
    "data_df['text'] = data_df['text'].apply(lowercase_except_all_caps)\n",
    "\n",
    "for i in range(10):\n",
    "    text = data_df[\"text\"][i]\n",
    "    label = data_df[\"label\"][i]\n",
    "\n",
    "    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb92a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove English Stop Words\n",
    "# data_df['text'] = data_df['text'].apply(remove_english_stopwords)\n",
    "\n",
    "# for i in range(10):\n",
    "#    text = data_df[\"text\"][i]\n",
    "#    label = data_df[\"label\"][i]\n",
    "\n",
    "#    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86e9cf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Filipino Stop Words\n",
    "# data_df['text'] = data_df['text'].apply(remove_filipino_stopwords)\n",
    "\n",
    "# for i in range(10):\n",
    "#    text = data_df[\"text\"][i]\n",
    "#    label = data_df[\"label\"][i]\n",
    "\n",
    "#    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f586bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Candidate Names\n",
    "# data_df['text'] = data_df['text'].apply(remove_candidate_names)\n",
    "\n",
    "# for i in range(10):\n",
    "    # text = data_df[\"text\"][i]\n",
    "    # label = data_df[\"label\"][i]\n",
    "\n",
    "    # print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2e98e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  napaka nonsense ng tanong sir walang substance next time sumagot ka ayun sa kong ano ang nasa isip at puso mo hindi galing sa script na binibigay sayo respect your choice pero sana suporthan nyo si leni robredo kahit wala na sya pakinabang sa mga dilawan \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  matapos tawaging spoiled child at weak leader tila nag-iba na ang pagtingin ni pres rodrigo duterte kay presidential bet bongbong marcos jr via \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  kaya di nag attend sa debate sponsored by SMNI si ma dumb leni robredo mapapahiya at mabubutata sya ni prof carlos \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  pangbatikos nila sa BBM initially bongbong marcos gaya ng ginawa nila dati sa DDS na dingdong dantes supporters \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  anyone could fit the bill there's jinggoy who's guilty of plunder and jv who has graft charges of course included din si bongbong marcos who's convicted of tax evasion pero hindi lang naman sya ang magnanakaw na tumatakbo ngayon \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  gumaganern basta umunlad ang pinas baka basta umunlad buhay ng mga marcos C'MON WE ALL KNOW WHAT BONGBONG AND FAM DID DON'T LIE TO URSELF HUN \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  ok si norberto gonzales at ernesto abella men of wisdom but lacks BBM has the energy and has true understanding and love for the country leody ok sana kaso baluktot ang pagintindi sa use of force ng gobyerno against sa kanila \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  disowning love ones cancelling businesses bullying someone because they're not supporting leni and badmouthing against BBM are the results of negative campaigns of kakampinks and leni robredo herself \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  dapat nga mga hipokritong katoliko mga botante at mga kabataan and mean who votes leni robredo and kiko that promotes hate and toxicity contrast with the message of jesus christ of love and unity think again hypocrites \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  bongbong marcos responses are really bland and abstract we don't want president who has no concrete and specific plans for our country we demand for president who is driven by experiences sincere and free from stains of corruption let that sink in \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove Hashtags\n",
    "data_df['text'] = data_df['text'].apply(remove_hashtags)\n",
    "    \n",
    "for i in range(10):\n",
    "    text = data_df[\"text\"][i]\n",
    "    label = data_df[\"label\"][i]\n",
    "    \n",
    "    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7eb4c5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  napaka nonsense ng tanong sir walang substance next time sumagot ka ayun sa kong ano ang nasa isip at puso mo hindi galing sa script na binibigay sayo respect your choice pero sana suporthan nyo si leni robredo kahit wala na sya pakinabang sa mga dilawan \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  matapos tawaging spoiled child at weak leader tila nag-iba na ang pagtingin ni pres rodrigo duterte kay presidential bet bongbong marcos jr via \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  kaya di nag attend sa debate sponsored by SMNI si ma dumb leni robredo mapapahiya at mabubutata sya ni prof carlos \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  pangbatikos nila sa BBM initially bongbong marcos gaya ng ginawa nila dati sa DDS na dingdong dantes supporters \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  anyone could fit the bill there's jinggoy who's guilty of plunder and jv who has graft charges of course included din si bongbong marcos who's convicted of tax evasion pero hindi lang naman sya ang magnanakaw na tumatakbo ngayon \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  gumaganern basta umunlad ang pinas baka basta umunlad buhay ng mga marcos C'MON WE ALL KNOW WHAT BONGBONG AND FAM DID DON'T LIE TO URSELF HUN \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  ok si norberto gonzales at ernesto abella men of wisdom but lacks BBM has the energy and has true understanding and love for the country leody ok sana kaso baluktot ang pagintindi sa use of force ng gobyerno against sa kanila \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  disowning love ones cancelling businesses bullying someone because they're not supporting leni and badmouthing against BBM are the results of negative campaigns of kakampinks and leni robredo herself \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  dapat nga mga hipokritong katoliko mga botante at mga kabataan and mean who votes leni robredo and kiko that promotes hate and toxicity contrast with the message of jesus christ of love and unity think again hypocrites \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Text:  bongbong marcos responses are really bland and abstract we don't want president who has no concrete and specific plans for our country we demand for president who is driven by experiences sincere and free from stains of corruption let that sink in \n",
      "\n",
      "Label:  Hate \n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove Hashtag Symbols\n",
    "data_df['text'] = data_df['text'].apply(remove_hashtag_symbols)\n",
    "\n",
    "for i in range(10):\n",
    "    text = data_df[\"text\"][i]\n",
    "    label = data_df[\"label\"][i]\n",
    "\n",
    "    print('Text: ', text, \"\\n\\nLabel: \", label, \"\\n\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63b091cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv('binary12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7cc88bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2536</td>\n",
       "      <td>napaka nonsense ng tanong sir walang substance...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1624</td>\n",
       "      <td>matapos tawaging spoiled child at weak leader ...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1008</td>\n",
       "      <td>kaya di nag attend sa debate sponsored by SMNI...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1637</td>\n",
       "      <td>pangbatikos nila sa BBM initially bongbong mar...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2264</td>\n",
       "      <td>anyone could fit the bill there's jinggoy who'...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>4766</td>\n",
       "      <td>sa gobyernong tapat angat buhay lahat ako si s...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>3929</td>\n",
       "      <td>the th president of the republic of the philip...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>4365</td>\n",
       "      <td>let's pray leni robredo amp kiko pangilinan fo...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>3896</td>\n",
       "      <td>titindig lalaban mananalo isang malaking karan...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>5017</td>\n",
       "      <td>aerial shot ng isinagawang miting de avance pa...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text     label\n",
       "0      2536  napaka nonsense ng tanong sir walang substance...      Hate\n",
       "1      1624  matapos tawaging spoiled child at weak leader ...      Hate\n",
       "2      1008  kaya di nag attend sa debate sponsored by SMNI...      Hate\n",
       "3      1637  pangbatikos nila sa BBM initially bongbong mar...      Hate\n",
       "4      2264  anyone could fit the bill there's jinggoy who'...      Hate\n",
       "...     ...                                                ...       ...\n",
       "5115   4766  sa gobyernong tapat angat buhay lahat ako si s...  Non-hate\n",
       "5116   3929  the th president of the republic of the philip...  Non-hate\n",
       "5117   4365  let's pray leni robredo amp kiko pangilinan fo...  Non-hate\n",
       "5118   3896  titindig lalaban mananalo isang malaking karan...  Non-hate\n",
       "5119   5017  aerial shot ng isinagawang miting de avance pa...  Non-hate\n",
       "\n",
       "[5120 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "364e034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['text'] = data_df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f32559d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2536</td>\n",
       "      <td>[18996, 11905, 14652, 12835, 9092, 5063, 2909,...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1624</td>\n",
       "      <td>[22640, 6873, 2015, 11937, 4213, 4726, 19582, ...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1008</td>\n",
       "      <td>[10905, 2050, 4487, 6583, 2290, 5463, 7842, 59...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1637</td>\n",
       "      <td>[20657, 14479, 12676, 2015, 9152, 2721, 7842, ...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2264</td>\n",
       "      <td>[3087, 2071, 4906, 1996, 3021, 2045, 1005, 105...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>4766</td>\n",
       "      <td>[7842, 2175, 3762, 11795, 5063, 11112, 4017, 1...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>3929</td>\n",
       "      <td>[1996, 16215, 2343, 1997, 1996, 3072, 1997, 19...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>4365</td>\n",
       "      <td>[2292, 1005, 1055, 11839, 18798, 2072, 6487, 2...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>3896</td>\n",
       "      <td>[14841, 7629, 4305, 2290, 21348, 19736, 2078, ...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>5017</td>\n",
       "      <td>[9682, 2915, 12835, 2003, 3981, 21188, 3070, 1...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text     label\n",
       "0      2536  [18996, 11905, 14652, 12835, 9092, 5063, 2909,...      Hate\n",
       "1      1624  [22640, 6873, 2015, 11937, 4213, 4726, 19582, ...      Hate\n",
       "2      1008  [10905, 2050, 4487, 6583, 2290, 5463, 7842, 59...      Hate\n",
       "3      1637  [20657, 14479, 12676, 2015, 9152, 2721, 7842, ...      Hate\n",
       "4      2264  [3087, 2071, 4906, 1996, 3021, 2045, 1005, 105...      Hate\n",
       "...     ...                                                ...       ...\n",
       "5115   4766  [7842, 2175, 3762, 11795, 5063, 11112, 4017, 1...  Non-hate\n",
       "5116   3929  [1996, 16215, 2343, 1997, 1996, 3072, 1997, 19...  Non-hate\n",
       "5117   4365  [2292, 1005, 1055, 11839, 18798, 2072, 6487, 2...  Non-hate\n",
       "5118   3896  [14841, 7629, 4305, 2290, 21348, 19736, 2078, ...  Non-hate\n",
       "5119   5017  [9682, 2915, 12835, 2003, 3981, 21188, 3070, 1...  Non-hate\n",
       "\n",
       "[5120 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "274bc204",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3706e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_dropout = nn.Dropout(dropout) \n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=256, kernel_size=2, padding='same')\n",
    "        self.pool1 = nn.MaxPool1d(2, 2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=256, out_channels=64, kernel_size=4, padding='same')\n",
    "        self.global_pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        x = embedded.permute(0, 2, 1)  # Change the dimensions for convolution\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.global_pooling(x).squeeze(2)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9d73f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up iterators\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7a9a6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, max_seq_length):\n",
    "        self.data = dataframe\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['text']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "\n",
    "        # Padding and conversion to tensor\n",
    "        padded_text = torch.tensor(text[:self.max_seq_length] + [0] * (self.max_seq_length - len(text)))\n",
    "        return padded_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2db27b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_df, 1000)\n",
    "test_dataset = TextDataset(test_df, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "782d32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_iterator = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce1934a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model hyperparameters\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "EMBEDDING_DIM = 768\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3, 4, 5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "\n",
    "# CNN Hyperparameters\n",
    "hidden_dim = 100\n",
    "n_conv_layers = 1\n",
    "kernel_sizes = [2, 3, 4]\n",
    "activation = nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "657020f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CNN model\n",
    "model = CNN(VOCAB_SIZE, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
    "#Initialize CNN model\n",
    "# model = CNN(VOCAB_SIZE, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, hidden_dim, n_conv_layers, kernel_sizes, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6896c237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.9, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.9, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.9, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize BERT model (for embedding extraction)\n",
    "bert_model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d06a906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, token in enumerate(tokenizer.get_vocab()):\n",
    "        token_id = tokenizer.convert_tokens_to_ids(token)\n",
    "        token_embedding = bert_model.embeddings.word_embeddings.weight[token_id]\n",
    "        model.embedding.weight[i].data.copy_(token_embedding)\n",
    "\n",
    "bert_parameters = []\n",
    "for layer in bert_model.encoder.layer:\n",
    "    bert_parameters.extend(layer.parameters())\n",
    "\n",
    "# Create AdamW optimizer with custom hyperparameters for BERT embeddings\n",
    "bert_learning_rate = 2e-4  # Adjust as needed\n",
    "bert_optimizer = optim.AdamW(bert_parameters, lr=bert_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc3596cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2536</td>\n",
       "      <td>[18996, 11905, 14652, 12835, 9092, 5063, 2909,...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1624</td>\n",
       "      <td>[22640, 6873, 2015, 11937, 4213, 4726, 19582, ...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1008</td>\n",
       "      <td>[10905, 2050, 4487, 6583, 2290, 5463, 7842, 59...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1637</td>\n",
       "      <td>[20657, 14479, 12676, 2015, 9152, 2721, 7842, ...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2264</td>\n",
       "      <td>[3087, 2071, 4906, 1996, 3021, 2045, 1005, 105...</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5115</th>\n",
       "      <td>4766</td>\n",
       "      <td>[7842, 2175, 3762, 11795, 5063, 11112, 4017, 1...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>3929</td>\n",
       "      <td>[1996, 16215, 2343, 1997, 1996, 3072, 1997, 19...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>4365</td>\n",
       "      <td>[2292, 1005, 1055, 11839, 18798, 2072, 6487, 2...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>3896</td>\n",
       "      <td>[14841, 7629, 4305, 2290, 21348, 19736, 2078, ...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>5017</td>\n",
       "      <td>[9682, 2915, 12835, 2003, 3981, 21188, 3070, 1...</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text     label\n",
       "0      2536  [18996, 11905, 14652, 12835, 9092, 5063, 2909,...      Hate\n",
       "1      1624  [22640, 6873, 2015, 11937, 4213, 4726, 19582, ...      Hate\n",
       "2      1008  [10905, 2050, 4487, 6583, 2290, 5463, 7842, 59...      Hate\n",
       "3      1637  [20657, 14479, 12676, 2015, 9152, 2721, 7842, ...      Hate\n",
       "4      2264  [3087, 2071, 4906, 1996, 3021, 2045, 1005, 105...      Hate\n",
       "...     ...                                                ...       ...\n",
       "5115   4766  [7842, 2175, 3762, 11795, 5063, 11112, 4017, 1...  Non-hate\n",
       "5116   3929  [1996, 16215, 2343, 1997, 1996, 3072, 1997, 19...  Non-hate\n",
       "5117   4365  [2292, 1005, 1055, 11839, 18798, 2072, 6487, 2...  Non-hate\n",
       "5118   3896  [14841, 7629, 4305, 2290, 21348, 19736, 2078, ...  Non-hate\n",
       "5119   5017  [9682, 2915, 12835, 2003, 3981, 21188, 3070, 1...  Non-hate\n",
       "\n",
       "[5120 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "02c4f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(model.parameters())\n",
    "# Your custom hyperparameters\n",
    "learning_rate = 0.001\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "epsilon = 1e-08\n",
    "weight_decay = 0.0\n",
    "\n",
    "# Create Adam optimizer with custom hyperparameters\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(beta_1, beta_2), eps=epsilon, weight_decay=weight_decay)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e33b7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train(model, iterator):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for text_batch, label_batch in iterator:\n",
    "        # Extract text sequences from the text_batch tensor\n",
    "        texts = text_batch\n",
    "        \n",
    "        # Extract and process labels\n",
    "        labels = [1 if label == 'Hate' else 0 for label in label_batch]  # Example conversion\n",
    "        \n",
    "        texts = texts.to(device)  # Move to device if needed\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).to(device)  # Convert to tensor\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(texts).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "# Evaluate function\n",
    "def evaluate(model, iterator):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []  # Declare the true_labels list\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch in iterator:\n",
    "            texts = text_batch  # Extract text sequences\n",
    "            labels = [1 if label == 'Hate' else 0 for label in label_batch]  # Example conversion\n",
    "            \n",
    "            texts = texts.to(device)  # Move to device\n",
    "            labels = torch.tensor(labels, dtype=torch.float32).to(device)  # Convert to tensor\n",
    "            \n",
    "            predictions = model(texts).squeeze(1)\n",
    "            loss = criterion(predictions, labels)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            predicted_labels.extend(torch.round(torch.sigmoid(predictions)).cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy, f1, precision, recall\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    \n",
    "    return epoch_loss / len(iterator), accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f3ec217d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:303: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\aten\\src\\ATen\\native\\Convolution.cpp:883.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.589\n",
      "\tTest Loss: 0.382\n",
      "\tAccuracy: 0.8252 | F1-Score: 0.8267\n",
      "\tPrecision: 0.8133 | Recall: 0.8406\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.336\n",
      "\tTest Loss: 0.285\n",
      "\tAccuracy: 0.8916 | F1-Score: 0.8909\n",
      "\tPrecision: 0.8900 | Recall: 0.8917\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.181\n",
      "\tTest Loss: 0.300\n",
      "\tAccuracy: 0.8809 | F1-Score: 0.8862\n",
      "\tPrecision: 0.8422 | Recall: 0.9350\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.115\n",
      "\tTest Loss: 0.279\n",
      "\tAccuracy: 0.8965 | F1-Score: 0.8942\n",
      "\tPrecision: 0.9069 | Recall: 0.8819\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.066\n",
      "\tTest Loss: 0.331\n",
      "\tAccuracy: 0.8955 | F1-Score: 0.8960\n",
      "\tPrecision: 0.8848 | Recall: 0.9075\n",
      "Epoch: 06\n",
      "\tTrain Loss: 0.049\n",
      "\tTest Loss: 0.432\n",
      "\tAccuracy: 0.8994 | F1-Score: 0.9024\n",
      "\tPrecision: 0.8702 | Recall: 0.9370\n",
      "Epoch: 07\n",
      "\tTrain Loss: 0.039\n",
      "\tTest Loss: 0.370\n",
      "\tAccuracy: 0.9004 | F1-Score: 0.8978\n",
      "\tPrecision: 0.9143 | Recall: 0.8819\n",
      "Epoch: 08\n",
      "\tTrain Loss: 0.037\n",
      "\tTest Loss: 0.423\n",
      "\tAccuracy: 0.9043 | F1-Score: 0.9054\n",
      "\tPrecision: 0.8883 | Recall: 0.9232\n",
      "Epoch: 09\n",
      "\tTrain Loss: 0.029\n",
      "\tTest Loss: 0.424\n",
      "\tAccuracy: 0.8965 | F1-Score: 0.8967\n",
      "\tPrecision: 0.8880 | Recall: 0.9055\n",
      "Epoch: 10\n",
      "\tTrain Loss: 0.019\n",
      "\tTest Loss: 0.525\n",
      "\tAccuracy: 0.9004 | F1-Score: 0.9034\n",
      "\tPrecision: 0.8704 | Recall: 0.9390\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_iterator)\n",
    "    test_loss, accuracy, f1, precision, recall = evaluate(model, test_iterator)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\tTest Loss: {test_loss:.3f}')\n",
    "    print(f'\\tAccuracy: {accuracy:.4f} | F1-Score: {f1:.4f}')\n",
    "    print(f'\\tPrecision: {precision:.4f} | Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee1e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dece720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da131100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
